{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 4.1 データセットと前処理\n",
    "\n",
    "このノートブックでは、第4.1節の内容に沿って、事前学習用のデータセット前処理パイプラインを実装します。\n",
    "\n",
    "- データ取得（Hugging Face datasets: globis-university/aozorabunko-clean）\n",
    "- テキスト正規化（neologdn + 全角半角変換）\n",
    "- 文書境界セパレータ付与＆連結\n",
    "- 学習用チャンク化（2048文字）\n",
    "- HuggingFace Dataset形式での保存\n",
    "\n",
    "トークナイザの学習・保存は4.3節で実施します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import neologdn\n",
    "from datasets import Dataset, DatasetDict, load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力先ディレクトリ\n",
    "OUTPUT_DIR = Path(\"data\")\n",
    "\n",
    "# 本文テキストのカラム名\n",
    "TEXT_COL = \"text\"\n",
    "\n",
    "# 文書境界セパレータ\n",
    "SEP = \"\\n\\n<|doc|>\\n\\n\"\n",
    "\n",
    "# チャンクサイズ（文字数）\n",
    "BLOCK_SIZE = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## データ取得（Hugging Face datasets）\n",
    "\n",
    "`globis-university/aozorabunko-clean` を取得します。青空文庫のテキストをもとにしたデータセットで、グロービス経営大学院が CC-BY ライセンスで公開しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945f7482a43a464d805bcf0edbf97b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037d9041486146d3b233cb56bd080a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aozorabunko-dedupe-clean.jsonl.gz:   0%|          | 0.00/241M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b696758c1cbd4a08a4c8e209d6847759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/16951 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データセット構成: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'footnote', 'meta'],\n",
      "        num_rows: 16951\n",
      "    })\n",
      "})\n",
      "train split のサンプル数: 16951\n"
     ]
    }
   ],
   "source": [
    "raw: DatasetDict = load_dataset(\"globis-university/aozorabunko-clean\")\n",
    "print(f\"データセット構成: {raw}\")\n",
    "print(f\"train split のサンプル数: {len(raw['train'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "深いおどろきにうたれて、\n",
      "名高いウェストミンスターに\n",
      "真鍮や石の記念碑となって\n",
      "すべての王侯貴族が集まっているのをみれば、\n",
      "今はさげすみも、ほこりも、見栄もない。\n",
      "善にかえった貴人の姿、\n",
      "華美と俗世の権勢をすてた\n",
      "けがれのない帝王の姿がみえるではないか。\n",
      "いろどられた、おもちゃのような墓石に\n",
      "今は静かに物云わぬ魂がどんなに満足していることか。\n",
      "かつてはその足にふまえた全世界をもってしても\n",
      "その欲望\n"
     ]
    }
   ],
   "source": [
    "# サンプルテキストを確認\n",
    "print(raw[\"train\"][0][TEXT_COL][:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## テキスト正規化\n",
    "\n",
    "日本語テキストには表記揺れが多く存在します。例えば：\n",
    "- ダッシュ `――` ↔ 長音符 `ー`\n",
    "- 全角英字 `Ｔ・Ｂ` ↔ 半角英字 `T・B`\n",
    "\n",
    "この種の差異は**語彙の分裂**を招き、学習効率を落とします。そこで、日本語向け正規化ライブラリ `neologdn` を用いて記号と全半角を機械学習寄りに揃えます。\n",
    "\n",
    "> 注意：文学テキストでは過度な正規化が作風（ダッシュのリズム、三点リーダ等）を損なうことがある。ここでは言語モデルの事前学習という目的を優先し、可読性より統計的一貫性を重視する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ja(text: str) -> str:\n",
    "    \"\"\"日本語テキストの正規化\n",
    "    \n",
    "    Args:\n",
    "        text: 入力テキスト\n",
    "    \n",
    "    Returns:\n",
    "        正規化されたテキスト\n",
    "    \"\"\"\n",
    "    # 1. neologdnによるデフォルト正規化\n",
    "    normalized_text = neologdn.normalize(text)\n",
    "\n",
    "    # 2. 全角英数 → 半角（A-Z/a-z/0-9 のみ最小実装）\n",
    "    def z2h_alnum(match):\n",
    "        ch = match.group(0)\n",
    "        return chr(ord(ch) - 0xFEE0)\n",
    "    normalized_text = re.sub(r\"[Ａ-Ｚａ-ｚ０-９]\", z2h_alnum, normalized_text)\n",
    "\n",
    "    # 3. クオートの半角化\n",
    "    normalized_text = normalized_text.replace(\"＂\", '\"').replace(\"＇\", \"'\")\n",
    "\n",
    "    # 4. 三点リーダの統一\n",
    "    normalized_text = normalized_text.replace(\"･･･\", \"…\").replace(\"・・・\", \"…\")\n",
    "\n",
    "    # 5. 連続空白の圧縮\n",
    "    normalized_text = re.sub(r\"\\s+\", \" \", normalized_text).strip()\n",
    "\n",
    "    return normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正規化前: ――「クリストレロの諷刺詩」一五九八年、Ｔ・Ｂ作\n",
      "正規化後: ー「クリストレロの諷刺詩」一五九八年、T・B作\n"
     ]
    }
   ],
   "source": [
    "# 正規化の動作確認\n",
    "test_text = \"――「クリストレロの諷刺詩」一五九八年、Ｔ・Ｂ作\"\n",
    "print(f\"正規化前: {test_text}\")\n",
    "print(f\"正規化後: {normalize_ja(test_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ab6500df994c279775290044c91a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "正規化処理:   0%|          | 0/16951 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正規化後のデータセット: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'footnote', 'meta'],\n",
      "        num_rows: 16951\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def apply_normalize(batch: dict) -> dict:\n",
    "    \"\"\"バッチ処理用の正規化関数\"\"\"\n",
    "    texts = batch[TEXT_COL]\n",
    "    return {TEXT_COL: [normalize_ja(t) for t in texts]}\n",
    "\n",
    "# データセット全体に適用（batched=True で速度改善）\n",
    "norm_ds = raw.map(\n",
    "    apply_normalize,\n",
    "    batched=True,\n",
    "    desc=\"正規化処理\",\n",
    ")\n",
    "\n",
    "print(f\"正規化後のデータセット: {norm_ds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "深いおどろきにうたれて、 名高いウェストミンスターに 真鍮や石の記念碑となって すべての王侯貴族が集まっているのをみれば、 今はさげすみも、ほこりも、見栄もない。 善にかえった貴人の姿、 華美と俗世の権勢をすてた けがれのない帝王の姿がみえるではないか。 いろどられた、おもちゃのような墓石に 今は静かに物云わぬ魂がどんなに満足していることか。 かつてはその足にふまえた全世界をもってしても その欲望\n"
     ]
    }
   ],
   "source": [
    "# 正規化後のサンプルを確認\n",
    "print(norm_ds[\"train\"][0][TEXT_COL][:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 文書境界セパレータ付与＆連結\n",
    "\n",
    "事前学習用に、文書間の境界を示すセパレータ `<|doc|>` を挿入しながら全文書を連結します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "連結後の総文字数: 227,624,821\n"
     ]
    }
   ],
   "source": [
    "def make_long_string(dsdict: DatasetDict, split: str, col: str = TEXT_COL) -> str:\n",
    "    \"\"\"データセットの全文書をセパレータで連結\n",
    "    \n",
    "    Args:\n",
    "        dsdict: データセット辞書\n",
    "        split: 使用するsplit名（'train'など）\n",
    "        col: テキストカラム名\n",
    "    \n",
    "    Returns:\n",
    "        連結されたテキスト\n",
    "    \"\"\"\n",
    "    texts = dsdict[split][col]\n",
    "    return SEP.join(texts)\n",
    "\n",
    "long_text = make_long_string(norm_ds, split=\"train\")\n",
    "print(f\"連結後の総文字数: {len(long_text):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最初のセパレータ位置: 10605\n",
      "セパレータ周辺のテキスト:\n",
      "。その生涯ははかない物語のようであり、その記念碑さえも廃墟となるのである。 原註トマス・ブラウン卿。\n",
      "\n",
      "<|doc|>\n",
      "\n",
      "いざ、これより樂しまむ、 仕置を受くる憂なく、 遊びたのしむ時ぞ來ぬ、 時ぞ來\n"
     ]
    }
   ],
   "source": [
    "# 連結結果のサンプルを確認（セパレータが含まれていることを確認）\n",
    "sep_pos = long_text.find(SEP)\n",
    "if sep_pos != -1:\n",
    "    print(f\"最初のセパレータ位置: {sep_pos}\")\n",
    "    print(f\"セパレータ周辺のテキスト:\\n{long_text[sep_pos-50:sep_pos+50]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 学習用チャンク化\n",
    "\n",
    "連結したテキストを固定長（2048文字）のチャンクに分割します。これはトークナイズ前の「プレトークナイズ」処理です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "チャンク数: 111,145\n",
      "最初のチャンクの長さ: 2048\n",
      "最後のチャンクの長さ: 1909\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(s: str, size: int):\n",
    "    \"\"\"テキストを固定長のチャンクに分割\n",
    "    \n",
    "    Args:\n",
    "        s: 入力テキスト\n",
    "        size: チャンクサイズ（文字数）\n",
    "    \n",
    "    Yields:\n",
    "        チャンク化されたテキスト\n",
    "    \"\"\"\n",
    "    for i in range(0, len(s), size):\n",
    "        yield s[i : i + size]\n",
    "\n",
    "# 文字列をBLOCK_SIZE文字ごとに分割\n",
    "chunks = list(chunk_text(long_text, BLOCK_SIZE))\n",
    "print(f\"チャンク数: {len(chunks):,}\")\n",
    "print(f\"最初のチャンクの長さ: {len(chunks[0])}\")\n",
    "print(f\"最後のチャンクの長さ: {len(chunks[-1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "深いおどろきにうたれて、 名高いウェストミンスターに 真鍮や石の記念碑となって すべての王侯貴族が集まっているのをみれば、 今はさげすみも、ほこりも、見栄もない。 善にかえった貴人の姿、 華美と俗世の権勢をすてた けがれのない帝王の姿がみえるではないか。 いろどられた、おもちゃのような墓石に 今は静かに物云わぬ魂がどんなに満足していることか。 かつてはその足にふまえた全世界をもってしても その欲望を満たすこともおさえることも出来なかったのに。 生とは冷たい幸福の結ぶ氷であり、 死とはあらゆる人間の虚栄をとかす霜解けである。 ー「クリストレロの諷刺詩」一五九八年、T・B作 秋も更けて、暁闇がすぐに黄昏となり、暮れてゆく年に憂愁をなげかけるころの、おだやかな、むしろ物さびしいある日、わたしはウェストミンスター寺院を逍遥して数時間すごしたことがある。悲しげな古い大伽藍の荘厳さには、この季節の感覚になにかぴったりするものがあった。その入口を通ったとき、わたしは、昔の人の住む国に逆もどりし、過ぎ去った時代の闇のなかに身を没してゆくような気がした。 わたしはウェストミンスター・スクールの中庭から入\n"
     ]
    }
   ],
   "source": [
    "# 最初のチャンクを確認\n",
    "print(chunks[0][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## HuggingFace Dataset形式で保存\n",
    "\n",
    "チャンク化したデータをHuggingFace Dataset形式で保存します。これにより、4.3節の事前学習でそのまま利用できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出力データセット: Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 111145\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Dataset形式化\n",
    "out_ds = Dataset.from_dict({\"text\": chunks})\n",
    "print(f\"出力データセット: {out_ds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f161d5b0b249a79f8c8644e93813e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/111145 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存先: data/aozora_preprocessed\n"
     ]
    }
   ],
   "source": [
    "# 保存\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "out_ds.save_to_disk(OUTPUT_DIR / \"aozora_preprocessed\")\n",
    "print(f\"保存先: {OUTPUT_DIR / 'aozora_preprocessed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 保存データの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "読み込んだデータセット: Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 111145\n",
      "})\n",
      "\n",
      "サンプルテキスト:\n",
      "深いおどろきにうたれて、 名高いウェストミンスターに 真鍮や石の記念碑となって すべての王侯貴族が集まっているのをみれば、 今はさげすみも、ほこりも、見栄もない。 善にかえった貴人の姿、 華美と俗世の権勢をすてた けがれのない帝王の姿がみえるではないか。 いろどられた、おもちゃのような墓石に 今は静かに物云わぬ魂がどんなに満足していることか。 かつてはその足にふまえた全世界をもってしても その欲望を満たすこともおさえることも出来なかったのに。 生とは冷たい幸福の結ぶ氷であり、 死とはあらゆる人間の虚栄をとかす霜解けである。 ー「クリストレロの諷刺詩」一五九八年、T・B作 秋も更けて、暁闇がすぐ\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "# 保存したデータを読み込んで確認\n",
    "loaded_ds = load_from_disk(OUTPUT_DIR / \"aozora_preprocessed\")\n",
    "print(f\"読み込んだデータセット: {loaded_ds}\")\n",
    "print(f\"\\nサンプルテキスト:\\n{loaded_ds[0]['text'][:300]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "このノートブックでは、以下の前処理パイプラインを実装しました：\n",
    "\n",
    "1. **データ取得**: Hugging Face datasets から青空文庫データを取得\n",
    "2. **テキスト正規化**: neologdn + 全角半角変換で表記揺れを統一\n",
    "3. **文書連結**: `<|doc|>` セパレータで全文書を連結\n",
    "4. **チャンク化**: 2048文字単位で分割\n",
    "5. **保存**: HuggingFace Dataset形式で保存\n",
    "\n",
    "次の4.3節では、このデータセットを用いてトークナイザの学習と事前学習を行います。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
