{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 人間のフィードバックによる学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データセットの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\n# データセット読み込み\nds = load_dataset(\"Anthropic/hh-rlhf\")\nds_train = ds[\"train\"]\nprint(f\"元のデータ数: {ds_train.num_rows}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hh-rlhfデータセットにはマルチターンの会話が含まれているため、シングルターンのデータのみをフィルタリングします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "シングルターンフィルタ後: 48591件\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/book-llm-from-scratch/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# シングルターンのデータのみフィルタリング\n",
    "def conversation_count_filter(example):\n",
    "    if example[\"chosen\"].count(\"Human: \") >= 2:\n",
    "        return False\n",
    "    if example[\"rejected\"].count(\"Human: \") >= 2:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "ds_train = ds_train.filter(conversation_count_filter)\n",
    "print(f\"シングルターンフィルタ後: {ds_train.num_rows}件\")\n",
    "\n",
    "# トークナイザーの準備\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preference Pairs の作成\n",
    "\n",
    "DPOでは、同じ入力に対する「好ましい応答（Chosen）」と「好ましくない応答（Rejected）」のペアを用意します。\n",
    "\n",
    "今回は、応答の先頭に「Let me explain. 」を付けたものをChosen、付けないものをRejectedとします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データ変換完了: 48201件\n",
      "\n",
      "【サンプル】\n",
      "Prompt: ### Question: If you were going to steal from a convenience store, do you think it would be better in the morning or at night?\n",
      "### Answer: \n",
      "Chosen: Let me explain. I really couldn’t say, I’m not familiar with stealing convenience store items.<|endo...\n",
      "Rejected: I really couldn’t say, I’m not familiar with stealing convenience store items.<|endoftext|>...\n"
     ]
    }
   ],
   "source": [
    "def extract_conversation(text):\n",
    "    \"\"\"会話から質問と応答を抽出\"\"\"\n",
    "    parts = text.split(\"Assistant: \")\n",
    "    if len(parts) < 2:\n",
    "        return \"\", \"\"\n",
    "    human = parts[0].replace(\"Human: \", \"\")\n",
    "    assistant = parts[1]\n",
    "    return human.strip(), assistant.strip()\n",
    "\n",
    "def create_preference_pairs(examples):\n",
    "    \"\"\"Preference Pairsを作成\"\"\"\n",
    "    new_examples = {\n",
    "        \"prompt\": [],\n",
    "        \"chosen\": [],\n",
    "        \"rejected\": [],\n",
    "    }\n",
    "    \n",
    "    for chosen_text in examples[\"chosen\"]:\n",
    "        human, answer = extract_conversation(chosen_text)\n",
    "        \n",
    "        if not human or not answer:\n",
    "            continue\n",
    "        \n",
    "        # 既に \"Let me explain\" で始まっている場合はスキップ\n",
    "        if answer.lower().startswith(\"let me explain\"):\n",
    "            continue\n",
    "        \n",
    "        # Chosen: \"Let me explain. \" + 応答\n",
    "        chosen = \"Let me explain. \" + answer + tokenizer.eos_token\n",
    "        # Rejected: 応答そのまま\n",
    "        rejected = answer + tokenizer.eos_token\n",
    "        # Prompt\n",
    "        prompt = f\"### Question: {human}\\n### Answer: \"\n",
    "        \n",
    "        new_examples[\"prompt\"].append(prompt)\n",
    "        new_examples[\"chosen\"].append(chosen)\n",
    "        new_examples[\"rejected\"].append(rejected)\n",
    "    \n",
    "    return new_examples\n",
    "\n",
    "# データ変換\n",
    "ds_train = ds_train.map(\n",
    "    create_preference_pairs,\n",
    "    batched=True,\n",
    "    remove_columns=ds_train.column_names\n",
    ")\n",
    "\n",
    "# 長さでフィルタリング（max_lengthを超えるものを除外）\n",
    "def filter_length(example):\n",
    "    prompt_len = len(tokenizer.encode(example[\"prompt\"]))\n",
    "    chosen_len = len(tokenizer.encode(example[\"chosen\"]))\n",
    "    return prompt_len <= 256 and prompt_len + chosen_len <= 512\n",
    "\n",
    "ds_train = ds_train.filter(filter_length)\n",
    "print(f\"データ変換完了: {len(ds_train)}件\")\n",
    "\n",
    "# サンプル確認\n",
    "print(f\"\\n【サンプル】\")\n",
    "print(f\"Prompt: {ds_train[0]['prompt']}\")\n",
    "print(f\"Chosen: {ds_train[0]['chosen'][:100]}...\")\n",
    "print(f\"Rejected: {ds_train[0]['rejected'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SFTモデルのロード\n",
    "\n",
    "5.2節でインストラクションチューニングしたモデルをロードします。DPOでは学習対象のモデルと参照モデル（ref_model）の2つが必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ローカルのSFTモデルを使用: ./output/sft_model\n",
      "パラメータ数: 124,439,808\n"
     ]
    }
   ],
   "source": [
    "# SFTモデルパスの設定\n",
    "local_sft_path = \"./output/sft_model\"\n",
    "hf_repo = \"elith/llm-book-models\"\n",
    "hf_sft_subfolder = \"chapter05/sft_model\"\n",
    "\n",
    "# ローカルに重みがあればそれを使用、なければHFからダウンロード\n",
    "if os.path.exists(os.path.join(local_sft_path, \"config.json\")):\n",
    "    print(f\"ローカルのSFTモデルを使用: {local_sft_path}\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(local_sft_path)\n",
    "    ref_model = AutoModelForCausalLM.from_pretrained(local_sft_path)\n",
    "else:\n",
    "    print(f\"Hugging FaceからSFTモデルをダウンロード: {hf_repo}/{hf_sft_subfolder}\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(hf_repo, subfolder=hf_sft_subfolder)\n",
    "    ref_model = AutoModelForCausalLM.from_pretrained(hf_repo, subfolder=hf_sft_subfolder)\n",
    "\n",
    "print(f\"パラメータ数: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DPOトレーナーの設定\n",
    "\n",
    "TRLライブラリのDPOTrainerを使用して学習を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac099a0477be478dab2d2902874a055c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/48201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import DPOTrainer, DPOConfig\n",
    "\n",
    "dpo_config = DPOConfig(\n",
    "    output_dir=\"./output/dpo_model\",\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=1e-5,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    beta=0.3,\n",
    "    max_length=512,\n",
    "    max_prompt_length=256,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=ref_model,\n",
    "    args=dpo_config,\n",
    "    train_dataset=ds_train,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 学習の実行\n",
    "\n",
    "以下のセルでDPO学習を実行します。\n",
    "\n",
    "> **注意**: GPUが必要です。GPUがない環境では学習セル（下記セル）をスキップし、「6. 学習済みモデルによる推論」へ進んでください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = trainer.train()\n",
    "\n",
    "print(f\"学習完了\")\n",
    "print(f\"最終loss: {result.training_loss:.4f}\")\n",
    "\n",
    "# モデル保存\n",
    "trainer.save_model(dpo_config.output_dir)\n",
    "print(f\"保存先: {dpo_config.output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 学習済みモデルによる推論\n",
    "\n",
    "学習をスキップした場合、または学習済みモデルで推論のみ行いたい場合は、以下のセルを実行してください。ローカルに重みがあればそれを使用し、なければ Hugging Face からダウンロードします。\n",
    "\n",
    "SFTモデルとDPOモデルの応答を比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ローカルのSFTモデルを使用: ./output/sft_model\n",
      "Hugging FaceからDPOモデルをダウンロード: elith/llm-book-models/chapter05/dpo_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/book-llm-from-scratch/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d30ce38a2d64d5bbf3f897b51f85bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/921 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812be727f47c414f979e1a74ff23579e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "デバイス: cuda\n"
     ]
    }
   ],
   "source": [
    "# モデルパスの設定\n",
    "local_sft_path = \"./output/sft_model\"\n",
    "local_dpo_path = \"./output/dpo_model\"\n",
    "hf_repo = \"elith/llm-book-models\"\n",
    "\n",
    "# SFTモデルのロード\n",
    "if os.path.exists(os.path.join(local_sft_path, \"config.json\")):\n",
    "    print(f\"ローカルのSFTモデルを使用: {local_sft_path}\")\n",
    "    sft_model = AutoModelForCausalLM.from_pretrained(local_sft_path)\n",
    "else:\n",
    "    print(f\"Hugging FaceからSFTモデルをダウンロード: {hf_repo}/chapter05/sft_model\")\n",
    "    sft_model = AutoModelForCausalLM.from_pretrained(hf_repo, subfolder=\"chapter05/sft_model\")\n",
    "\n",
    "# DPOモデルのロード\n",
    "if os.path.exists(os.path.join(local_dpo_path, \"config.json\")):\n",
    "    print(f\"ローカルのDPOモデルを使用: {local_dpo_path}\")\n",
    "    dpo_model = AutoModelForCausalLM.from_pretrained(local_dpo_path)\n",
    "else:\n",
    "    print(f\"Hugging FaceからDPOモデルをダウンロード: {hf_repo}/chapter05/dpo_model\")\n",
    "    dpo_model = AutoModelForCausalLM.from_pretrained(hf_repo, subfolder=\"chapter05/dpo_model\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dpo_model = dpo_model.to(device)\n",
    "sft_model = sft_model.to(device)\n",
    "print(f\"デバイス: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SFTモデル vs DPOモデル\n",
      "============================================================\n",
      "\n",
      "【質問】What is machine learning?\n",
      "\n",
      "[SFTモデル]\n",
      "Machine learning is a field of science that focuses on the development of algorithms that can be used to model, predict, and predict the behavior of h...\n",
      "\n",
      "[DPOモデル]\n",
      "Let me explain. Machine learning is a field that focuses on solving complex problems using algorithms that are trained on real-world data.  Machine le...\n",
      "\n",
      "'Let me explain'で開始: 成功\n",
      "------------------------------------------------------------\n",
      "\n",
      "【質問】Explain the artificial intelligence\n",
      "\n",
      "[SFTモデル]\n",
      "Artificial Intelligence (AI) is a term used to describe a group of artificial intelligence (AI) that is trained on a computer and can perform complex ...\n",
      "\n",
      "[DPOモデル]\n",
      "Let me explain. Artificial intelligence is a term coined by Elon Musk to describe a group of people who believe that artificial intelligence is a good...\n",
      "\n",
      "'Let me explain'で開始: 成功\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 推論関数\n",
    "@torch.inference_mode()\n",
    "def generate_response(model, question, max_new_tokens=100):\n",
    "    prompt = f\"### Question: {question}\\n### Answer: \"\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    generated = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated.split(\"### Answer: \")[1].strip()\n",
    "\n",
    "# テスト質問\n",
    "test_questions = [\n",
    "    \"What is machine learning?\",\n",
    "    \"Explain the artificial intelligence\",\n",
    "]\n",
    "\n",
    "# 比較\n",
    "print(\"=\" * 60)\n",
    "print(\"SFTモデル vs DPOモデル\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\n【質問】{question}\")\n",
    "    \n",
    "    sft_response = generate_response(sft_model, question)\n",
    "    dpo_response = generate_response(dpo_model, question)\n",
    "    \n",
    "    print(f\"\\n[SFTモデル]\")\n",
    "    print(f\"{sft_response[:150]}...\")\n",
    "    \n",
    "    print(f\"\\n[DPOモデル]\")\n",
    "    print(f\"{dpo_response[:150]}...\")\n",
    "    \n",
    "    # 確認\n",
    "    has_explain = dpo_response.lower().startswith(\"let me explain\")\n",
    "    status = \"成功\" if has_explain else \"失敗\"\n",
    "    print(f\"\\n'Let me explain'で開始: {status}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}