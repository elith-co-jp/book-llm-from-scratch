{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "\n",
    "from llm_from_scratch.transformer.transformer import Encoder, Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"small_parallel_enja\")\n",
    "if not data_dir.exists():\n",
    "    !git clone https://github.com/odashi/small_parallel_enja.git {data_dir}\n",
    "\n",
    "train_ja = data_dir / \"train.ja.000\"\n",
    "train_en = data_dir / \"train.en.000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "\n",
    "def iter_corpus(\n",
    "    path: Path,\n",
    "    bos: str | None = \"<bos>\",\n",
    "    eos: str | None = \"<eos>\",\n",
    ") -> Iterator[list[str]]:\n",
    "    with path.open(\"r\") as f:\n",
    "        for line in f:\n",
    "            if bos:\n",
    "                line = bos + \" \" + line\n",
    "            if eos:\n",
    "                line = line + \" \" + eos\n",
    "            yield line.split()\n",
    "\n",
    "\n",
    "train_tokens_ja = [tokens for tokens in iter_corpus(train_ja)]\n",
    "train_tokens_en = [tokens for tokens in iter_corpus(train_en)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_tokens_ja[:3])\n",
    "print(train_tokens_en[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_ja = build_vocab_from_iterator(\n",
    "    iterator=train_tokens_ja,\n",
    "    specials=(\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"),\n",
    ")\n",
    "vocab_ja.set_default_index(vocab_ja[\"<unk>\"])\n",
    "vocab_en = build_vocab_from_iterator(\n",
    "    iterator=train_tokens_en,\n",
    "    specials=(\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"),\n",
    ")\n",
    "vocab_en.set_default_index(vocab_en[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"<unk>:\", vocab_ja[\"<unk>\"])\n",
    "tokens = [\"<bos>\", \"吾輩\", \"は\", \"猫\", \"で\", \"ある\", \"<eos>\"]\n",
    "for token in tokens:\n",
    "    print(vocab_ja[token], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchtext import transforms\n",
    "\n",
    "src_transforms = transforms.Sequential(\n",
    "    transforms.VocabTransform(vocab_ja),\n",
    "    transforms.ToTensor(padding_value=vocab_ja[\"<pad>\"]),\n",
    ")\n",
    "tgt_transforms = transforms.Sequential(\n",
    "    transforms.VocabTransform(vocab_en),\n",
    "    transforms.ToTensor(padding_value=vocab_en[\"<pad>\"]),\n",
    ")\n",
    "\n",
    "\n",
    "def collate_fn(batch: Tensor) -> tuple[Tensor, Tensor]:\n",
    "    src_texts, tgt_texts = [], []\n",
    "    for s, t in batch:\n",
    "        src_texts.append(s)\n",
    "        tgt_texts.append(t)\n",
    "\n",
    "    src_texts = src_transforms(src_texts)\n",
    "    tgt_texts = tgt_transforms(tgt_texts)\n",
    "\n",
    "    return src_texts, tgt_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    list(zip(train_tokens_ja, train_tokens_en)),\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "src_texts, tgt_texts = batch\n",
    "print(src_texts.shape)\n",
    "print(tgt_texts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(pad_id: int, batch_tokens: Tensor):\n",
    "    mask = batch_tokens == pad_id\n",
    "    mask = mask.unsqueeze(1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_subsequent_mask(batch_tokens: Tensor):\n",
    "    sequence_len = batch_tokens.size(1)\n",
    "    mask = torch.triu(\n",
    "        torch.full((sequence_len, sequence_len), 1),\n",
    "        diagonal=1,\n",
    "    )\n",
    "    mask = mask == 1\n",
    "    mask = mask.unsqueeze(0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device, \"を使用\")\n",
    "\n",
    "embedding_dim = 512\n",
    "n_blocks = 6\n",
    "n_heads = 8\n",
    "expansion_rate = 1\n",
    "\n",
    "# 語彙数を取得\n",
    "src_vocab_size = len(vocab_ja)\n",
    "tgt_vocab_size = len(vocab_en)\n",
    "\n",
    "# 最も長い文章の長さを取得\n",
    "max_len_ja = len(max(train_tokens_ja, key=lambda x: len(x)))\n",
    "max_len_en = len(max(train_tokens_en, key=lambda x: len(x)))\n",
    "max_length = max(max_len_ja, max_len_en)\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size,\n",
    "    tgt_vocab_size,\n",
    "    max_sequence_len=max_length,\n",
    "    d_model=embedding_dim,\n",
    "    n_blocks=n_blocks,\n",
    "    n_heads=n_heads,\n",
    "    d_k=embedding_dim,\n",
    "    d_v=embedding_dim,\n",
    "    d_ff=embedding_dim * expansion_rate,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_ID = vocab_ja[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_ID)  # クロスエントロピー\n",
    "lr = 0.0001  # 学習率\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, log_interval: int = 10) -> list[float]:\n",
    "    model.train()\n",
    "    loss_history = []\n",
    "    for i, (src_texts, tgt_texts) in enumerate(train_loader):\n",
    "        # tgt の入力は最後の単語を除く\n",
    "        tgt_input = tgt_texts[:, :-1]\n",
    "        # tgt の出力は最初の単語を除く\n",
    "        tgt_output = tgt_texts[:, 1:]\n",
    "        src_mask = create_padding_mask(PAD_ID, src_texts)\n",
    "        tgt_mask1 = create_padding_mask(PAD_ID, tgt_input)\n",
    "        tgt_mask2 = create_subsequent_mask(tgt_input)\n",
    "        tgt_mask = tgt_mask1 + tgt_mask2\n",
    "        # Tensor のデバイスを設定\n",
    "        src_texts, tgt_input, tgt_output = (\n",
    "            src_texts.to(device),\n",
    "            tgt_input.to(device),\n",
    "            tgt_output.to(device),\n",
    "        )\n",
    "        src_mask, tgt_mask = src_mask.to(device), tgt_mask.to(device)\n",
    "\n",
    "        # モデル出力を取得\n",
    "        out = model(src_texts, tgt_input, src_mask, tgt_mask, src_mask)\n",
    "        # 出力と教師データを1次元に変換\n",
    "        out_flat = out.view(-1, out.size(-1))\n",
    "        tgt_flat = tgt_output.flatten()\n",
    "        # 誤差関数を計算\n",
    "        loss = criterion(out_flat, tgt_flat)\n",
    "        optimizer.zero_grad()\n",
    "        # 誤差逆伝播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i + 1) % log_interval == 0:\n",
    "            print(f\"step {i+1}: train loss = {loss.item()}\")\n",
    "        loss_history.append(loss.item())\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "n_epochs = 20  # エポック数\n",
    "pbar = tqdm(total=n_epochs)\n",
    "for epoch in range(n_epochs):\n",
    "    pbar.update(1)\n",
    "    pbar.set_description(desc=\"Epoch\")\n",
    "    train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"<bos> 今日 の 天気 は 晴れ です 。 <eos>\"\n",
    "tokens = text.split()\n",
    "input_tokens = src_transforms([tokens]).to(device)\n",
    "tgt_tokens = model.inference(input_tokens, bos_token=vocab_ja[\"<bos>\"])\n",
    "itos = vocab_en.get_itos()\n",
    "text = \" \".join(itos[token_id] for token_id in tgt_tokens[0])\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
