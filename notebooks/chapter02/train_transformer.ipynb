{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "\n",
    "from llm_from_scratch.transformer.transformer import Encoder, Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"small_parallel_enja\")\n",
    "if not data_dir.exists():\n",
    "    !git clone https://github.com/odashi/small_parallel_enja.git {data_dir}\n",
    "\n",
    "train_ja = data_dir / \"train.ja.000\"\n",
    "train_en = data_dir / \"train.en.000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "\n",
    "tokenizer_ja = get_tokenizer(None)  # split するだけ\n",
    "tokenizer_en = get_tokenizer(tokenizer=\"basic_english\")  # lower して split\n",
    "\n",
    "Tokenizer = Callable[[str], list[str]]\n",
    "\n",
    "\n",
    "def iter_corpus(\n",
    "    path: Path,\n",
    "    tokenizer: Tokenizer,\n",
    "    bos: str | None = \"<bos>\",\n",
    "    eos: str | None = \"<eos>\",\n",
    ") -> Iterator[list[str]]:\n",
    "    with path.open(\"r\") as f:\n",
    "        for line in f:\n",
    "            if bos:\n",
    "                line = bos + \" \" + line\n",
    "            if eos:\n",
    "                line = line + \" \" + eos\n",
    "            yield tokenizer(line)\n",
    "\n",
    "\n",
    "train_tokens_ja = [tokens for tokens in iter_corpus(train_ja, tokenizer_ja)]\n",
    "train_tokens_en = [tokens for tokens in iter_corpus(train_en, tokenizer_en)]\n",
    "\n",
    "vocab_ja = build_vocab_from_iterator(\n",
    "    iterator=train_tokens_ja,\n",
    "    specials=(\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"),\n",
    ")\n",
    "vocab_ja.set_default_index(vocab_ja[\"<unk>\"])\n",
    "vocab_en = build_vocab_from_iterator(\n",
    "    iterator=train_tokens_en,\n",
    "    specials=(\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"),\n",
    ")\n",
    "vocab_en.set_default_index(vocab_en[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchtext import transforms\n",
    "\n",
    "src_transforms = transforms.Sequential(\n",
    "    transforms.VocabTransform(vocab_ja),\n",
    "    transforms.ToTensor(padding_value=vocab_ja[\"<pad>\"]),\n",
    ")\n",
    "tgt_transforms = transforms.Sequential(\n",
    "    transforms.VocabTransform(vocab_en),\n",
    "    transforms.ToTensor(padding_value=vocab_en[\"<pad>\"]),\n",
    ")\n",
    "\n",
    "\n",
    "def collate_fn(batch: Tensor) -> tuple[Tensor, Tensor]:\n",
    "    src_texts, tgt_texts = [], []\n",
    "    for s, t in batch:\n",
    "        src_texts.append(s)\n",
    "        tgt_texts.append(t)\n",
    "\n",
    "    src_texts = src_transforms(src_texts)\n",
    "    tgt_texts = tgt_transforms(tgt_texts)\n",
    "\n",
    "    return src_texts, tgt_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = TranslationDataset(train_tokens_ja, train_tokens_en)\n",
    "train_loader = DataLoader(\n",
    "    list(zip(train_tokens_ja, train_tokens_en)),\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_ID = vocab_ja[\"<pad>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(pad_id: int, batch_tokens: Tensor):\n",
    "    mask = batch_tokens == pad_id\n",
    "    mask = mask.unsqueeze(1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_subsequent_mask(batch_tokens: Tensor):\n",
    "    sequence_len = batch_tokens.size(1)\n",
    "    mask = torch.triu(\n",
    "        torch.full((sequence_len, sequence_len), 1),\n",
    "        diagonal=1,\n",
    "    )\n",
    "    mask = mask == 1\n",
    "    mask = mask.unsqueeze(0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_ja = len(max(train_tokens_ja, key=lambda x: len(x)))\n",
    "max_len_en = len(max(train_tokens_en, key=lambda x: len(x)))\n",
    "max_length = max(max_len_ja, max_len_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 512\n",
    "n_blocks = 6\n",
    "n_heads = 8\n",
    "expansion_rate = 4\n",
    "src_vocab_size = len(vocab_ja)\n",
    "tgt_vocab_size = len(vocab_en)\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size,\n",
    "    tgt_vocab_size,\n",
    "    max_sequence_len=max_length,\n",
    "    d_model=embedding_dim,\n",
    "    n_blocks=n_blocks,\n",
    "    n_heads=n_heads,\n",
    "    d_k=embedding_dim,\n",
    "    d_v=embedding_dim,\n",
    "    d_ff=embedding_dim * expansion_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_ID)\n",
    "lr = 0.001  # learning rate\n",
    "n_epochs = 100\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def train(model: nn.Module, log_interval: int = 10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, (src_texts, tgt_texts) in enumerate(train_loader):\n",
    "        src_mask = create_padding_mask(PAD_ID, src_texts)\n",
    "        tgt_mask1 = create_padding_mask(PAD_ID, tgt_texts)\n",
    "        tgt_mask2 = create_subsequent_mask(tgt_texts)\n",
    "        tgt_mask = tgt_mask1 + tgt_mask2\n",
    "\n",
    "        out = model(src_texts, tgt_texts, src_mask, tgt_mask, src_mask)\n",
    "        out_flat = out.view(-1, tgt_vocab_size)\n",
    "        tgt_flat = tgt_texts.view(-1)\n",
    "        loss = criterion(out_flat, tgt_flat)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if (i + 1) % log_interval == 0:\n",
    "            print(f\"step {i+1}: train loss = {loss.item()}\")\n",
    "\n",
    "\n",
    "pbar = tqdm(total=n_epochs)\n",
    "for epoch in range(n_epochs):\n",
    "    pbar.update(1)\n",
    "    pbar.set_description(desc=\"Epoch\")\n",
    "    train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
