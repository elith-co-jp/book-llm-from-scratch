# <sup>第</sup>4<sup>章</sup>

### 大規模言語モデルの 学習

**前章では 2017年に発表された Transformerを発展させて、 GPT-2相当の大規模言語モデル( LLM)の開発と他のモデル の紹介をしました。本章では、大規模化が進んでいるモデルを どのようなデータセットで、どのように学習するべきかについて 説明します。実務で LLMを学習する際には Transformersや DeepSpeedといったライブラリが利用されます。本書は LLM をイチから作るというコンセプトですが、実際の研究・開発ではこ れらのライブラリが使えることが重要になります。そこで、本章は 個別の技術についてはイチから作りつつ、全体を通した動くコー ドとしてはライブラリを利用したものを提示します。**

★いただいたものが長かったこともあり、原稿を修正しています。 確認&修正をお願いします。

## 4.1 データセットと前処理

### 4.1.1 言語モデルの大規模化

 大規模言語モデル(LLM)の性能は、モデル規模(パラメータ数)、学習データ量、そして計算量の 増加に伴って向上することが知られています。この経験則を定量的に記述したものが Scaling law (スケーリング則)です。スケーリング則によれば、資源を投入すればするほど性能は向上しますが、そ の向上幅は次第に逓減していきます。従って、「資源を増やせばよい」という単純な図式ではなく、限 られた計算資源をいかに最適に配分するかが重要となります。

 このとき注目すべき指標が、スループット(throughput)とトークン効率(token efficiency)です。 スループットは、単位時間あたりに処理可能なトークン数を表し、実際の学習速度を規定します。ここ で留意すべき点は、理論的に必要とされる計算量(FLOPs)と、ハードウェアが実際に発揮し得る計 算性能(FLOPS)、さらにそこから得られる処理速度(throughput)が必ずしも一致しないということ です。学習効率を論じる際には、この乖離を踏まえる必要があります。

 一方、トークン効率は「どれだけ少ない学習トークンで目標性能を実現できるか」を示す指標であり、 データセットの設計や学習戦略の巧拙を直接反映します。単なるモデル拡張に頼るのではなく、いか に効率的にデータを活用するかが問われるのです。

 こうした効率性の観点を統合的に検討したものが、DeepMindによる Chinchilla law(チンチラ 則)です。チンチラ則は、限られた計算資源のもとでは、パラメータ数を増大させるよりも、十分に大き なデータセットを用いて学習させる方が望ましいことを明示しました。すなわち、FLOPsを「モデルの 拡張」に振り向けるのではなく、「データの拡充」に投じる方が高いトークン効率を得られるという指針 です。

 このように、スケーリング則による拡張の原理、スループットとトークン効率という計算効率の視座、さ らにチンチラ則による資源配分の最適化指針が重なり合うことで、LLMの学習設計は初めて理論的 な基盤を得るのです。次節では、その基盤の上に位置づけられる大規模データセットの準備と設計に ついて検討します。

#### 4.1.2 大規模言語モデルのデータセット

#### 事前学習コーパス

 事前学習コーパスとは、言語モデルの事前学習に使用する大量のテキストデータのことを指しま す。これは、言語モデルが実世界のテキストデータから広範な知識を獲得するための基盤となるもの で、通常、他のデータセットに比べて圧倒的な規模を持ちます。事前学習の段階では、モデルは大量 のラベルなしテキストデータを利用して、言語の文法や意味、文脈に関する一般的な知識を学び、そ れをモデルの内部パラメータに組み込みます。これにより、言語モデルは多様な言語タスクにおいて 一定の理解力と生成能力を発揮できるようになります。

#### 事前学習コーパスの構成要素

 事前学習に使用されるコーパスは、多様なソースから取得したものです。その中には、Webページ、 学術論文、書籍、法律文書、政府報告書、さらには小説や新聞記事まで含まれます。これらのソース は、モデルに幅広い知識を提供するだけでなく、異なる文体やトーン、専門用語など、言語の多様性 を反映したデータを供給します。

 さらに、特定の分野に特化したデータセットも多く存在します。例えば、医学、法律、金融などの専門 分野では、それぞれの分野に特化したテキストデータが収集され、モデルがその分野に特有の知識 を学習できるようにします。

#### 事前学習コーパスの種類

 事前学習コーパスは、その目的や特性に基づいて、一般的なコーパスとドメイン固有のコーパスに 分類されます。

#### 1. 一般的な事前学習コーパス

 このタイプのコーパスは、幅広い分野やトピックをカバーするテキストデータで構成され ており、ニュース記事、ソーシャルメディア投稿、ブログ、百科事典などが含まれます。こうし たコーパスは、言語モデルに普遍的な言語理解力を持たせることを目的としています。多様 なデータソースを使用することで、モデルは異なる文脈での言語使用を学び、汎用性の高い 言語処理能力を獲得します。

#### 2. ドメイン固有の事前学習コーパス

 こちらは、特定の専門分野に関連するデータで構成されたコーパスです。医学、法律、技 術、金融などの専門領域で使用されることが多く、それぞれの分野に特有の知識や用語をモ デルに学習させます。この種のコーパスは、特定のタスクで高精度なモデルを作成するため に不可欠です。例えば、医療分野のコーパスを用いたモデルは、診断支援システムや医学論 文の要約などで優れた成果を発揮します。

#### 事前学習コーパスの役割と影響

 事前学習コーパスは、モデルの性能や適用範囲に直接的な影響を与えます。以下にその主な役 割を挙げます。

- ・普遍的な言語理解の基盤: 多様なテキストデータを取り込むことで、モデルは言語の文法、 意味、文脈情報を包括的に学習し、自然言語の理解を深めます。これにより、異なるタスク においても一貫したパフォーマンスを発揮できます。
- ・汎化能力の向上: 異なる分野やトピックから得られるデータを利用することで、モデルは広 範な知識を獲得し、未知のデータやタスクにも適応できる能力が高まります。これにより、新 しいタスクや環境での利用が可能となります。
- ・専門分野での高精度なタスク実行: ドメイン固有のコーパスを用いることで、特定分野での タスクに対してモデルの精度が向上します。例えば、法律文書を大量に含むコーパスで訓練 されたモデルは、契約書の自動解析や法的助言などに特化した能力を持ちます。
- ・多言語処理の支援: 複数の言語をカバーするコーパスを利用することで、モデルは多言語 間での文脈理解や翻訳タスクに対応できるようになります。これにより、国際的な言語タス クにおいても高いパフォーマンスを発揮できます。
- ・文化的多様性の反映: さまざまな文化圏からのデータを取り込むことで、モデルは異なる文 化的背景を理解し、文化に依存した言語表現やニュアンスをより正確に処理できるようにな ります。これにより、より多様なユーザに対して適切な応答が可能となります。

#### 事前学習コーパスの進化と現状

 事前学習コーパスの進化は、言語モデルの性能向上に密接に関連しています。初期の言語モデ ルは、比較的限定的なデータセットを使用していましたが、近年の LLMは、数十テラバイト規模のデー タセットを活用しています。このような大規模データセットの利用により、モデルは以前よりも、はるかに 広範な知識と高い性能を持つようになっています。

 例えば、「Common Crawl」は、インターネット全体を網羅的にクロールして得られたデータを含む 巨大なコーパスであり、現代の多くの LLMがこのデータセットを基盤として訓練されています。また、 「OSCAR」や「CC100」などは、多言語データを提供するコーパスであり、多言語対応のモデルを訓 練する際に使用されます。

 さらに、最新の研究では、コーパスに含まれるデータの質やバランスがモデルの性能に与える影響 についても注目が集まっています。例えば、偏ったデータセットはモデルにバイアスを生じさせる可能性

があり、その結果、特定の集団や言語に対して不公平な処理を行うリスクがあります。このため、デー タの選定やフィルタリングプロセスも非常に重要な要素となっています。

 表4.1.1に、一般的に使用される事前学習コーパスを示します。これらのコーパスは、それぞれ異な る言語やデータソースから構成されており、言語モデルの訓練において重要なリソースを提供してい ます。

#### 表4.1.1 主な事前学習コーパス

| コーパス         | 言語        | データ容量         | データ情報      |
|--------------|-----------|---------------|------------|
| Common Crawl | 多言語       | -             | ウェブページ(雑多) |
| CC100        | 多言語       | 2.5TB         | ウェブページ(雑多) |
| C4           | 英語        | 12.7TB        | ウェブページ(雑多) |
| mC4          | 多言語       | 251GB         | ウェブページ(雑多) |
| OSCAR        | 多言語       | 8.4TB         | ウェブページ(雑多) |
| CulturaX     | 多言語       | 27.0TB        | ウェブページ(雑多) |
| RedPajama-V2 | 多言語       | 30.4 T Tokens |            |
| S2ORC        | 英語        | 81.1MB        | 論文         |
| The Stack    | プログラミング言語 | 6TB           | コード        |
| Wikipedia    | 多言語       | -             | 百科事典(雑多)   |
| FinGLM       | 中国        | 69.0GB        | 金融         |
| Medical-pt   | 中国        | 632.8MB       | 医療         |
| Proof-Pile-2 | 英語        | 55 B Tokens   | 数学/コード     |
| 青空文庫         | 日本語       | -             | 書籍         |

#### インストラクションチューニングデータセット

 LLMは、膨大なテキストデータを使用した事前学習によって、言語に関する豊富な知識を獲得し、 高度な自然言語処理能力を身につけています。しかし、特定のタスクに適用するためには、追加の学 習が必要であり、これをファインチューニングと呼びます。

 ファインチューニングには、タスクに特化したデータセットを使用することが重要です。この種のデー タセットは、ユーザの指示に従って応答を生成するために設計されており、インストラクションデータセッ トと呼ばれます。インストラクションデータは、特定のタスクに対する「指示入力」とそれに対応する「応 答出力」のペアで構成されています。指示には、要約、質問応答、翻訳など多様なタスクが含まれ、応 答はその指示に従ってモデルが生成する結果です。

インストラクションデータの作成方法には、主に 2つのアプローチがあります。1つめは、人間が手動

で作成する方法です。この方法では、高品質で人間の意図に合致したデータを得られますが、その 反面、作成には膨大な時間とコストがかかるという課題があります。もう1つは、LLM自身がデータを 生成する方法です。このアプローチでは、大量のデータを短時間で生成できますが、データの品質が 一定しない場合があり、人間の直感とは異なる結果が得られることもあります。

 インストラクションデータの元となるデータソースとしては、既存のデータセットの活用や、テーブル データのような構造化されたデータの変換が挙げられます。また、タスクの種類も多岐にわたり、具体 的には以下のようなタスクがあります。

・Closed QA: 提供された質問に基づいて、正しい選択肢を選択する。

・Open QA: 提供された質問に基づいて、適切な回答を生成する。

・要約: 与えられた文章を簡潔にまとめる。

・生成: 指示に基づいて新たなテキストを一から生成する。

・翻訳: 異なる言語間での翻訳を行う。

・数学: 数学に関する問題を解く。

・コード: コードの生成、修正、理解など、プログラミングに関連する問題を解決する。

 これらのタスクを処理するために、多くのインストラクションデータセットが存在します。以下にその例 を示します。

表4.1.2 主なインストラクションデータセット

| データセット名                    | 言語  | 作成方法    | データ数 |
|----------------------------|-----|---------|------|
| databricks-dolly-15K       | 英語  | 人手      | 15k  |
| databricks-dolly-15k-ja    | 日本語 | 人手+翻訳AI | 15k  |
| OASST1                     | 多言語 | 人手      | 161k |
| Alpaca_data                | 英語  | LLM     | 52k  |
| ichika-instruction-003-001 | 日本語 | 人手      | 3k   |

 これらのデータセットを用いてモデルをファインチューニングすることで、モデルは特定のタスクにお ける意図を理解し、適切な応答を生成する能力が得られます。モデルのパラメータを適切に調整する ことで、一般的な言語知識を維持しつつ、特定のタスクに特化した能力を持たせられるのです。

#### 嗜好データセット

 嗜好データセットは、特定の指示に対する複数の回答に対して、どの選択肢がより好ましいかを示 すデータの集合です。これらのデータセットは、指示に対する異なる回答ペアと、それに対する人間や

高度な LLMからのフィードバックで構成されています。このフィードバックにより、特定のタスクや文脈 においてどの回答が相対的に適切であるかを判断できます。

 選好を評価する方法はいくつかあります。例えば、投票、ソート、スコアリングといった比較方法です。 これらの手法は、選好を明確に表現するために、人間の評価者や LLMによって行われます。嗜好 データセットは特に、LLMのアライメントプロセスで利用され、人間の期待や基準により近い出力を生 成するためにモデルを調整する際に重要な役割を果たします。

 人間からのフィードバックは、現実世界での選好や直感に基づいており、モデルの出力を現実的な ものに近づけるために有用です。しかし、その一方で、個々の評価者の主観性や、異なる評価者間の 一貫性の欠如といった問題が生じる可能性があります。また、このプロセスは手間がかかり、コストが 高くなることもあります。

 一方、LLMによるフィードバックは、事前に学習された広範な知識を活用し、迅速かつ低コストでの アノテーションが可能です。ただし、LLM固有のバイアスが含まれるリスクや、人間によるフィードバック と比較して信頼性が劣る可能性もあります。そのため、LLMのトレーニングには、さまざまな形式とソー スから得られた選好データを組み合わせる、包括的なアプローチが効果的とされています。

 さらに、強化学習を取り入れた手法、特に RLHF(Reinforcement Learning from Human Feedback)は、これらのフィードバック信号に基づいてモデルを最適化するための強力なツールで す。この手法により、モデルはフィードバックを活用して自己改善を行い、より人間に近い応答を生成で きます。

 代表的な嗜好データセットを表4.1.3に示します。これらのデータセットは、言語モデルの性能向上に 寄与するための重要なリソースであり、各データセットは特定の言語やタスクに焦点を当てています。

表4.1.3 主な嗜好データセット

| データセット名                     | 言語  | データ数 |
|-----------------------------|-----|------|
| Chatbot_arena_conversations | 多言語 | 33k  |
| hh-rljf                     | 英語  | 169k |
| hh-rlhf-49k-ja              | 日本語 | 49k  |
| OASST1_pairwise_rlhf_reward | 多言語 | 19k  |
| Stack-Exchange-Preferences  | 英語  | 11M  |
| Alpaca_comparison_data      | 英語  | 51k  |

 これらのデータセットを使用することで、モデルは多様な状況における人間の好みを理解し、より洗 練された出力を生成することが期待されます。

#### 4.1.3 データの前処理

 LLMの学習に使われるデータはインターネットから集めたものなど、文章としての質が担保されて いない場合が多いです。また、文章としての質が良くても個人情報や機密情報を含んでいる場合は 削除しておかないと、LLM利用時に出力されてしまうといった問題もあります。

 以上のような問題に対処するために、収集されたデータセットはそのまま使うのではなく、前処理を 行った後に利用します。よく用いられる前処理は以下の 4つです。

- ・テキスト正規化
- ・品質フィルタリング
- ・重複除去
- ・プライバシー保護

以降ではこの 4つについて具体的にどのような方法が用いられているのかを説明します。

 テキスト正規化はテキストに含まれるスペースや、カギ括弧の種類などをそろえる処理のことです。 これらの表記揺れは、LLM の学習時にはノイズになってしまうので除去する必要があります。ここで は、 neologdnというライブラリを利用して、テキスト正規化を試してみましょう。

#### コード4.1.1 neologdnを用いたテキスト正規化コード

```
import neologdn
def neologdn_preprocess(text):
 # 1. neologdnによるデフォルト正規化
 normalization_text = neologdn.normalize(text)
 return normalization_text
```

 品質フィルタリングは、低品質のテキストを学習データから除外する処理です。この処理では以下 の 3通りの方法が用いられます。

- 1. ヒューリスティックを用いた手法
- 2. 分類モデルを用いたの手法
- 3. LLM を用いた手法

 ヒューリスティックを用いた手法というのは、特定のキーワードを含んでいたら除外する、統計的特 徴に基づいて除外するといった手法です。

 分類モデルを用いた手法は、テキストの品質を評価する機械学習モデルが別途学習しておき、そ のモデルの判定結果をもとにテキストを除外します。

 LLMを用いた手法ではパープレキシティ**1**のような評価指標を基準として、不自然な文章を除外し ます。

 重複除去は名前の通り、重複するテキストを除外する処理です。この処理は主に 2つの理由から 行われます。

- ・学習データに重複が含まれるとモデルの能力に悪影響を与える可能性がある
- ・学習データとテストデータを分けた際に、重複があると適切に評価できない

 重複除去は、文書レベル、文レベル等の複数のレベルで行われます。文書レベルでは、文書に関す る特徴量をもとに同じような文書が検出されます。文レベルでは、反復フレーズなどが検出されます。

 最後にプライバシー保護では、電話番号、氏名、住所といった個人情報や、パスワード、シークレット キーといった機密情報を検出し削除します。このような情報の検出は正規表現を用いたルールベース の手法や、固有表現抽出 (Named Entity Recognition、NER) と呼ばれる自然言語処理タスクを 解く機械学習モデルを利用した方法が用いられます。ただし、これらの方法でも完全には除外しきれ ないため、次章で扱うアラインメントによって、個人情報を聞かれても答えないようにチューニングする ことも重要になります。

#### 4.1.4 前処理の実装

 ここでは 4.2節以降の事前学習で利用するデータセットを作成します。簡単のため、複雑な前処理 は完了しているデータとして、青空文庫のテキストをもとにした globis-university/aozorabunkoclean データセット**2**を利用します。

**<sup>1</sup>** 次章で詳しく説明します。ここでは、LLM にとっての与えられた文章の自然さと捉えてください

**<sup>2</sup>** https://huggingface.co/datasets/globis-university/aozorabunko-clean、グロービス経営大学院が CC-BYライセンスで公開。

**生とは冷たい幸福の結ぶ氷であり、 死とはあらゆる人間の虚栄をとかす霜解けである。 ――「クリストレロの諷刺詩」一五九八年、T・B作**

```
生とは冷たい幸福の結ぶ氷であり、
死とはあらゆる人間の虚栄をとかす霜解けである。
ー「クリストレロの諷刺詩」一五九八年、T・B作
```

違いの例を示します。

- ・ダッシュ `**――** ` ↔ 長音符 `**ー**`
- ・全角英字 `**T・B**` ↔ 半角英字 `**T・B**`

 この種の差異は語彙の分裂を招き、学習効率を落とします。そこで、本節では日本語向け正規化ラ イブラリ(例:neologdn)を用いて記号と全半角を機械学習寄りにそろえます **<sup>3</sup>**。

#### コード4.1.2 前処理のコード

```
# データセットのロード
raw: DatasetDict = load_dataset("globis-university/aozorabunko-clean")
# 本文テキストのカラム名
TEXT_COL = "text"
def normalize_ja(text):
 # 1. neologdnによるデフォルト正規化
 normalized_text = neologdn.normalize(text)
 # 全角英数 → 半角(A-Z/a-z/0-9 のみ最小実装)
 def z2h_alnum(match):
 ch = match.group(0)
 return chr(ord(ch) - 0xFEE0)
 normalized_text = re.sub(r"[A-Za-z0-9]", z2h_alnum, normalized_text)
 # クオートの半角化(任意)
 normalized_text = normalized_text.replace(""", '"').replace("'", "'")
```

**<sup>3</sup>** 文学テキストでは過度な正規化が作風(ダッシュのリズム、三点リーダ等)を損なうことがあります。ここでは言語モデ ルの事前学習という目的を優先し、可読性より統計的一貫性を重視します。

第4章

```
 # 三点リーダの統一
 normalized_text = normalized_text.replace("・・・", "…").replace("・・・", "…")
 # 連続空白の圧縮
 normalized_text = re.sub(r"\s+", " ", normalized_text).strip()
 return normalized_text
# データセット全体に適用
def apply_normalize(batch):
 texts = batch[TEXT_COL]
 return {TEXT_COL: [normalize_ja(t) for t in texts]}
# batched=True で速度改善、説明を付与
norm_ds = raw.map(
 apply_normalize,
 batched=True,
)
# 文書境界セパレータ付与&連結
# 事前学習用に文書間の境界を示すセパレータ
SEP = "\n\n<|doc|>\n\n"
def make_long_string(dsdict, split, , col=TEXT_COL):
 # DataSetsの列アクセスは高速なので、そのままスライスで取り出す
 texts = dsdict[split][col] 
 # 空文字などがあっても素直に連結
 return SEP.join(texts)
long_text = make_long_string(norm_ds, split="train")
# 学習用チャンク化(プレトークナイズ前)
block_size = 2048
def chunk_text(s: str, size: int):
 # ここでは単純に「文字数」で分割
 for i in range(0, len(s), size):
 yield s[i : i + size]
# 文字列を 2048文字ごとに分割し、Dataset形式化
chunks = list(chunk_text(long_text, block_size))
out_ds = Dataset.from_dict({"text": chunks})
```