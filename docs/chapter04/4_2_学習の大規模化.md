# 4.2 学習の大規模

大規模モデルを学習する場合、複数の GPU を用いて効率的に学習する必要があります。ここでは、3つの並列化手法と、ZeRO と呼ばれるメモリ効率を上げる手法について紹介します。前半ではこれらの手法についての説明と、PyTorch を用いた個別の実装を示します。その後、これらの手法を含む高度な分散学習をサポートするフレームワークである、Megatron-DeepSpeed の利用方法を説明します。

## 4.2.1 GPU を利用した学習

第2章の Transformer の学習でも、GPU は利用していました。本節では、複数 GPU を利用するため、ここで必要な用語を整理と、全体に共通する事柄の説明を行います。

まず、複数の GPU がある場合について説明します。複数の GPU を利用する際は、以下の2通りの状況がありえます。

- 1つのコンピュータ上の複数の GPU を利用する
- 複数のコンピュータ上の GPU を利用する

この時、各コンピュータのことをノードと呼びます。複数 GPU を利用する計算では、計算結果をまとめるために GPU 間での通信が発生します。ノード内での通信は比較的高速にできるものの、ノードをまたいだ通信には時間がかかります。そのため、全体で同じ数の GPU を利用する場合は1ノード内で完結している方が好ましいです。しかし、実際は 1 つのノード内の GPU では足りない場合もあり、複数ノードを利用することになります。

GPU の ID は各ノード内で管理されます。これに対して、ノードをまたいで付与される ID を Rank と呼びます。このイメージを [<図: 複数ノードがある場合の GPU ID>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) に示します。ノード1でも GPU の ID は 0, 1 になっていますが、Rank は 2, 3 になっていることに注意してください。

![<図: 複数ノードがある場合の GPU ID>](https://prod-files-secure.s3.us-west-2.amazonaws.com/f32ca4cc-631d-41b4-b55a-d4b4b3d47037/b67282d0-e9df-4263-a68b-9fe3f6bec9ba/%E3%82%A2%E3%83%BC%E3%83%88%E3%83%9B%E3%82%99%E3%83%BC%E3%83%88%E3%82%99_52x.png)

<図: 複数ノードがある場合の GPU ID>

図の例では全体で GPU が 4 個ありました。このような全体での GPU の数を World Size と呼びます。

## 4.2.2 データ並列

学習の効率化といった場合、以下の2通りが考えられます。

- **時間効率化**: 短い時間で学習できる
- **空間効率化**: (1GPUあたりの) メモリ使用量を抑えて学習できる

データ並列 (Data Parallel) は、これらのうち、時間効率化にあたります。そのため、1GPU あたりに使用されるメモリ量は、並列化しない場合と同等程度になります。

1つの GPU に載るサイズのモデルを学習する場合はどのように学習時間を短縮していたでしょうか。最も簡単な方法はバッチサイズを大きくすることです。これは、GPU 上で並列に計算されるデータ量が増え、モデルがより早く全てのデータを見終わるためです。例えば、データ数が 128 でバッチサイズが 32 だと、合計で 4 周計算する必要がありますが、バッチサイズが 64 であれば 2 周ですみます。

データ並列はこのアイディアを、複数 GPU で行うことで計算を効率化します。複数の GPU でデータを処理するため、モデルは [<図: データ並列の概念図>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) のようにコピーされます。 

![<図: データ並列の概念図>](https://prod-files-secure.s3.us-west-2.amazonaws.com/f32ca4cc-631d-41b4-b55a-d4b4b3d47037/7bb3528b-cfcf-4456-8fc4-5e72bb4e4ac0/%E3%82%A2%E3%83%BC%E3%83%88%E3%83%9B%E3%82%99%E3%83%BC%E3%83%88%E3%82%99_22x.png)

<図: データ並列の概念図>

ここで、新たにローカルバッチ・グローバルバッチという単語が現れました。これは、通常の学習におけるバッチと同様に、データセットを適当なサイズに分割したものです。データ並列では、これをさらに分割して各 GPU に割り当てます。そのため、大元のバッチをグローバルバッチ、GPU ごとに割り当てられるバッチをローカルバッチとして区別します。

データ並列化を行った際の処理の流れを [<図: データ並列時の処理の流れ>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) に示します。

![<図: データ並列時の処理の流れ>](https://prod-files-secure.s3.us-west-2.amazonaws.com/f32ca4cc-631d-41b4-b55a-d4b4b3d47037/88e20044-ef1d-45d9-9ff0-0b4706f77381/%E3%82%A2%E3%83%BC%E3%83%88%E3%83%9B%E3%82%99%E3%83%BC%E3%83%88%E3%82%99_62x.png)

<図: データ並列時の処理の流れ>

モデル並列時の学習では、順伝播と逆伝播 (勾配の計算) はそれぞれの GPU 内で行われます。一方、モデルを更新する際は、各 GPU で計算された勾配の平均値を用いて更新するため、GPU 間の通信が必要になります。通信は 1つの GPU がホストとなって各 GPU がホストとやりとりをする方法や、それぞれの GPU 同士でやりとりをする方法があります。また、更新自体も全ての GPU の計算が終了するのを待つ同期型と、計算が終わり次第更新する非同期型がありますが、これらについての説明は本書の範疇を越えるため省略します。

計算リソースが無限にある場合、グローバルバッチをとにかく大きくして、全てのデータを 1 周の計算で使えば良いでしょうか。答えは NO です。これは、単一の GPU で学習する場合にもいえることですが、バッチサイズを大きくしすぎると、むしろ収束が遅くなってしまうことが知られています。実際はこのような問題が顕在化するほどの計算リソースを利用できることはほぼありませんので、このことについては知識として知っておく程度で良いでしょう。

第2章で作成した Transformer の学習をデータ並列を用いて並列化してみましょう。学習の本体である train 関数を示す前に、それを呼び出している main 関数を確認します ( [<コード: データ並列を用いた学習コードの main 関数>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) )。

```python
def main():
    n_gpu = 4
    batch_size = 64
    n_epochs = 10
    data_dir = Path("small_parallel_enja")
    train_dataset, dataset_info = load_dataset(data_dir)
    os.environ["MASTER_ADDR"] = "localhost"
    os.environ["MASTER_PORT"] = "12355"
    mp.spawn(
        train,
        args=(n_gpu, batch_size, n_epochs, train_dataset, dataset_info),
        nprocs=n_gpu,
        join=True,
    )
```

環境変数に設定している `MASTER_ADDR` は、マルチノードで学習する際に必要になるものです。マルチノード学習の場合は、マスタープロセスと呼ばれる実行の中心になるようなプロセスが動いているノードのアドレスを指定する必要があります。今回はシングルノードなので localhost を指定しています。同様に `MASTER_PORT` はマスタープロセスが動いているノードで通信に利用できるポートを指定します。

`mp` は `import torch.multiprocessing as mp` のようにインポートしたモジュールで、並列化のようなマルチプロセスの処理を扱います。 `mp.spawn` 関数に各ランクで実行させたい関数 ( `train` ) と引数を渡すことで並列処理を実行します。

`train` 関数を [<コード: データ並列を用いた学習コード>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) に示します。 `mp.spawn` で並列実行される関数ですが、完全に独立に動いているわけではなく、誤差逆伝播の際など適宜他の GPU との連携を行っています。PyTorch ではこのような通信に関して開発者が管理しなくてもデータ並列のコードが書けるように実装されています。

```python
def train(rank, n_gpu, batch_size, n_epochs, train_dataset, dataset_info):
		#1. GPU に関する設定
    init_process_group("nccl", rank=rank, world_size=n_gpu)
    torch.manual_seed(0)
    torch.cuda.set_device(rank)
    # create local model
    embedding_dim = 512
    n_blocks = 6
    n_heads = 8
    expansion_rate = 1

    # 最も長い文章の長さを取得
    model = Transformer(
	    # Transformer の引数
	    # ...
    ).to(rank)
    #2. ここで各 rank の GPU にモデルを配置
    model = DDP(model, device_ids=[rank])

    #3. rank ごとにデータを分割するためのサンプラーを作成
    sampler = DistributedSampler(
        train_dataset, num_replicas=n_gpu, rank=rank, shuffle=True
    )
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        sampler=sampler,
        collate_fn=dataset_info["collate_fn"],
    )

    PAD_ID = dataset_info["vocab_src"]["<pad>"]
    criterion = nn.CrossEntropyLoss(ignore_index=PAD_ID)  # クロスエントロピー
    lr = 0.0001  # 学習率
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10.0, gamma=0.95)
    pbar = tqdm(total=n_epochs, desc=f"rank{rank}", position=rank)
    for epoch in range(n_epochs):
        pbar.update(1)
        for i, (src_texts, tgt_texts) in enumerate(train_loader):
            # マスクや入出力の準備
            # ...
            #4. Tensor のデバイスを設定
            src_texts, tgt_input, tgt_output = (
                src_texts.to(rank),
                tgt_input.to(rank),
                tgt_output.to(rank),
            )
            src_padding_mask, tgt_mask = src_padding_mask.to(rank), tgt_mask.to(rank)

            # モデル出力の計算
            # ...
            # 損失関数の計算と誤差逆伝播
            # ...
        scheduler.step()
		#5. モデルの保存
    if rank == 0:
        torch.save(model.state_dict(), "transformer.pth")

```

`#...` と記載している部分は、第2章の内容からほぼ変わっていないため省略しています。大きく変わった部分の直前には #1 から #4 のように数字を割り振っています。

まず #1 では、 `init_process_group` でバックエンド、現在のプロセスが World Size 中のどのランクにあたるかを指定しています。バックエンドというのは、GPU 間の通信を実際に扱うライブラリで、 nccl、gloo、mpi の3つが指定可能です。速度やサポートする機能の多さから、GPU で利用する際は nccl を指定する場合が多いです。 `set_device` では、 `rank` 番目の GPU を利用するように設定しています。

#2 は、モデルをデータ並列で学習するための設定です。#3 は、データをローカルバッチに分解するためのクラスを作成しています。学習ループの中の #4 では、データを `rank` で指定されたデバイスに載せています。単一の GPU の場合はここで `rank` ではなく `"cuda"` を指定していました。

最後の #5 は、モデルの保存です。データ並列では、各ランクのデバイスでモデルが共有されているため、ランクが 0 の場合のみモデルを保存する様に書きます。

## 4.2.3 テンソル並列

テンソル並列と、後述する パイプライン並列はどちらもモデル並列とよばれる並列化の一種です。データ並列ではデータを複数の GPU に分解して計算していたのに対し、モデル並列ではモデルを複数の GPU に分解して計算します。そのため、モデルサイズを固定した状況では、並列数を増やすほど各 GPU が持つパラメータの数が減り、メモリ使用量を抑えることができます。この技術によって 1 つの GPU には乗り切らなかった数十億、数百億パラメータを超える大規模言語モデルの学習が可能になります。

テンソル並列は [<図: テンソル並列>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) に示すように、モデルを縦 ▲注▲ に割くような並列化です。

- ▲注▲
    
    縦か横かは図の書き方によりますが、本書の図に従って縦としています。
    

![<図: テンソル並列>](https://prod-files-secure.s3.us-west-2.amazonaws.com/f32ca4cc-631d-41b4-b55a-d4b4b3d47037/75e03131-1693-4a02-b229-34182d3c5ca9/%E3%82%A2%E3%83%BC%E3%83%88%E3%83%9B%E3%82%99%E3%83%BC%E3%83%88%E3%82%99_72x.png)

<図: テンソル並列>

実際は完全に分割できているわけではなく、図中における濃い線と薄い線の部分の計算を別々の GPU で行うようなイメージです。図からもわかるように、GPU0 側の計算にも GPU1 側のユニット (丸い部分) からの入力が必要になります。そのため、図の様なテンソル並列では各レイヤーを計算するごとに出力を共有するための通信が発生します。

この通信は、単一の GPU で計算しているときには必要のないものでした。このように、モデル並列は、より大きなモデルを学習できるようになる反面、適切に設計しなければ時間効率は低くなってしまいます。

1層目のテンソル並列を数式でも確認してみましょう。

入力を $\bm x = (x_1, x_2, \ldots, x_6)$ として、次のレイヤーのユニット $i$ につながる重みベクトルを$\boldsymbol w_i$ とします。 このとき、出力$(y_1, y_2, \ldots, y_6)$ を得るための計算は、[<図: テンソル並列の数式>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) に示した様に、$(y_1, y_2, y_3)$ の計算と $(y_4, y_5, y_6)$の計算に分けることができます。

![<図: テンソル並列の数式>](https://prod-files-secure.s3.us-west-2.amazonaws.com/f32ca4cc-631d-41b4-b55a-d4b4b3d47037/aa8ae353-c379-42dd-ab12-c92c903047d7/%E3%82%A2%E3%83%BC%E3%83%88%E3%83%9B%E3%82%99%E3%83%BC%E3%83%88%E3%82%99_152x.png)

<図: テンソル並列の数式>

[<図: テンソル並列>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) に示した並列化では、2層目の計算時に1層目の出力を全 GPU で共有する必要がありました。これを改善するためには、[<図: 改善したテンソル並列>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) のように分解することができます。

![<図: 改善したテンソル並列>](https://prod-files-secure.s3.us-west-2.amazonaws.com/f32ca4cc-631d-41b4-b55a-d4b4b3d47037/ca184077-e061-4f19-9caa-20af15b1ac8b/%E3%82%A2%E3%83%BC%E3%83%88%E3%83%9B%E3%82%99%E3%83%BC%E3%83%88%E3%82%99_712x.png)

<図: 改善したテンソル並列>

図の真ん中のユニットは入力側も出力側もそれぞれの濃い線または薄い線のみになっていることに注目してください。このように分解すれば、2層の MLP（多層パーセプトロン）では最終出力の計算以外で計算結果の共有が発生せず、効率的なテンソル並列が可能になります。

効率的なテンソル並列を数式で表すと [<図: 効率的なテンソル並列の数式表現>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) のようになります。

![<図: 効率的なテンソル並列の数式表現>](https://prod-files-secure.s3.us-west-2.amazonaws.com/f32ca4cc-631d-41b4-b55a-d4b4b3d47037/6677f4f1-ebc3-4e7b-ba7e-ab9a8ce9bebf/%E3%82%A2%E3%83%BC%E3%83%88%E3%83%9B%E3%82%99%E3%83%BC%E3%83%88%E3%82%99_722x.png)

<図: 効率的なテンソル並列の数式表現>

数式中で、$W_1$ (1層目) と $W_2$ (2層目) の分解方法が列方向と行方向といった形で変わっていることが見て取れます。このように、同じ線形レイヤーでもどの方向に分解するべきかが状況に応じて変わります。そのため、テンソル並列はモデルのアーキテクチャに応じて適切に設計する必要があるため、データ並列と比べると難易度が高くなります。

次に、PyTorch を用いた実装を確認します。まず、デバイスメッシュと呼ばれる、GPU 同士をどのように連携させるかの定義を行います。これについては本書では深くは扱いません。ここでは、シングルノード 4 GPU での学習を行うため [<コード: メッシュの定義とランクの取得>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) のように指定してください。

```python
from torch.distributed.device_mesh import init_device_mesh
tp_mesh = init_device_mesh("cuda", (4,))
rank = tp_mesh.get_rank() # コードが動いているプロセスの GPU ランクを取得
```

おおまかなコードの流れはデータ並列と同様ですが、大幅に異なるのがモデル作成後の、レイヤーごとの並列化方法を定義する部分です。該当箇所を [<コード: レイヤーの並列化方法の定義>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) に示します。

```python
    # レイヤーごとに並列化の方法を定義
    for module in [model.encoder, model.decoder]:
        # エンコーダ・デコーダのブロック
        for block in module.blocks:
            tp_plan_block = {
                "attention.linear_o": RowwiseParallel(),
                "feed_forward.0": ColwiseParallel(),
                "feed_forward.2": RowwiseParallel(),
            }
            parallelize_module(
                module=block,
                device_mesh=tp_mesh,
                parallelize_plan=tp_plan_block,
            )
            # マルチヘッドアテンションのヘッドごと
            for attention in block.attention.heads:
                tp_plan_attention = {
                    "linear_q": ColwiseParallel(),
                    "linear_k": ColwiseParallel(),
                    "linear_v": ColwiseParallel(),
                }
                parallelize_module(
                    module=attention,
                    device_mesh=tp_mesh,
                    parallelize_plan=tp_plan_attention,
                )
```

すでに説明した様に、テンソル並列には列方向と行方向の分解がありました。PyTorch ではこれが、 `torch.distributed.tensor.parallel` の `ColwiseParallel` と `RowwiseParallel` として用意されています。これらを用いて、レイヤーを分解する方法を辞書の形で定め、同じモジュール内の `parallelize_module` 関数に  `parallelize_plan` として渡します。これによって、プログラムがモデルをどの様に分解すれば良いか認識できます。

他は概ねデータ並列と同様ですが、ここでは `mp.spawn` を利用しないため、main 関数は [<コード: テンソル並列時のmain 関数>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) のようになります。

```python
def main():
    device = "cuda"
    data_dir = Path("small_parallel_enja")
    train_dataset, dataset_info = load_dataset(data_dir)

    train(
        batch_size=64,
        n_epochs=10,
        train_dataset=train_dataset,
        dataset_info=dataset_info,
        device=device,
    )
    if rank == 0:
        print(torch.cuda.max_memory_allocated())
```

最後の `torch.cuda.max_memory_allocated` は、そのプログラムが動いている間に利用された GPU メモリの最大値を返す関数です。並列化しない場合や、並列数を変更した場合と比べてどの様に変換するかを確認してみてください。

テンソル並列のコードをシングルノード4GPUで実行するには、<コード: テンソル並列の実行コマンド例> に示す torchrun コマンドを利用します。

```python
torchrun --standalone --nproc_per_node=4 section02_tensor_parallel.py
```

`--standalone` はシングルノードを用いることや特定のバックエンドを指定するコマンドで、 `—nproc_per_node` はノードごとのプロセス数を指定します。ここでは 4 GPU なので 4 と指定しています。

実行してみると学習に非常に時間がかかったのではないでしょうか。今回は簡易的に作成した Transformer モデルのフィードフォワード層とマルチヘッドアテンションのみ並列化しています。実際には `ColwiseParallel` や `RowwiseParallel` に加えて `SequenceParallel` を用いたレイヤー正規化や、 `loss_parallel` を用いた損失関数の並列化も行います。余力がある読者は、これらを用いてより適切なテンソル並列の設計に挑戦してみてください。

## 4.2.4 パイプライン並列

テンソル並列はモデルを縦に割く並列化であると説明しました。これに対してパイプライン並列は[<図: パイプライン並列>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) に示すようにモデルを横に割くような並列化です。

![<図: パイプライン並列>](https://prod-files-secure.s3.us-west-2.amazonaws.com/f32ca4cc-631d-41b4-b55a-d4b4b3d47037/6bc3a39c-6e16-4aa9-81b1-d1c531f13c5f/%E3%82%A2%E3%83%BC%E3%83%88%E3%83%9B%E3%82%99%E3%83%BC%E3%83%88%E3%82%99_82x.png)

<図: パイプライン並列>

2GPU の場合、この並列化での計算の流れは次のようになります。

1. 最初のレイヤーを GPU0 で計算
2. 計算結果を GPU1 に転送
3. 2つ目のレイヤーを GPU 1 が計算
4. GPU1 で誤差逆伝播
5. 誤差情報を GPU0 に転送
6. GPU 0 で誤差逆伝播

GPU が 4 つある状況で、この計算の流れを示したのが [<図: パイプライン並列の処理の流れ>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) です。F や B で表したのがそれぞれのレイヤーにおける順伝播や逆伝播のバッチ計算です。 

![<図: パイプライン並列の処理の流れ>](https://prod-files-secure.s3.us-west-2.amazonaws.com/f32ca4cc-631d-41b4-b55a-d4b4b3d47037/0dc5fc9e-d16f-419b-9ca0-26dccbf8b0eb/%E3%82%A2%E3%83%BC%E3%83%88%E3%83%9B%E3%82%99%E3%83%BC%E3%83%88%E3%82%99_212x.png)

<図: パイプライン並列の処理の流れ>

この様な計算は、[<図: バケツリレーの様子 (a)>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) に示すバケツリレーに例えることができます。バケツが処理中のデータで、運ぶ人が GPU になります。

![<図: バケツリレーの様子 (a) パイプライン中の t1>](https://prod-files-secure.s3.us-west-2.amazonaws.com/f32ca4cc-631d-41b4-b55a-d4b4b3d47037/64116ac6-63a7-493d-8d71-73f309b9be32/%E3%82%A2%E3%83%BC%E3%83%88%E3%83%9B%E3%82%99%E3%83%BC%E3%83%88%E3%82%99_182x.png)

<図: バケツリレーの様子 (a) パイプライン中の t1>

![<図: バケツリレーの様子 (b) パイプライン中の t3>](https://prod-files-secure.s3.us-west-2.amazonaws.com/f32ca4cc-631d-41b4-b55a-d4b4b3d47037/2df301cc-ca65-40b2-b684-9f6747a03f5c/%E3%82%A2%E3%83%BC%E3%83%88%E3%83%9B%E3%82%99%E3%83%BC%E3%83%88%E3%82%99_192x.png)

<図: バケツリレーの様子 (b) パイプライン中の t3>

![<図: バケツリレーの様子 (c) パイプライン中の t6>](https://prod-files-secure.s3.us-west-2.amazonaws.com/f32ca4cc-631d-41b4-b55a-d4b4b3d47037/017e2950-d348-4eab-b61c-602ee6b3a497/%E3%82%A2%E3%83%BC%E3%83%88%E3%83%9B%E3%82%99%E3%83%BC%E3%83%88%E3%82%99_202x.png)

<図: バケツリレーの様子 (c) パイプライン中の t6>

図からも分かる様に、GPU1 がバケツを運んでいる時、GPU0, GPU2, GPU3 は何もしていません。この状態では計算リソースが無駄になってしまうので、[<図: バケツリレーの様子 (b)>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) のようにバケツを小さくして、少しずつ運ぶのはどうでしょうか。このような小さく分けたバケツのことを、マイクロバッチと呼びます。

マイクロバッチを用いたパイプラインを [<図: パイプライン並列のミニバッチを分割>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) に示します。

![<図: パイプライン並列のミニバッチを分割>](https://prod-files-secure.s3.us-west-2.amazonaws.com/f32ca4cc-631d-41b4-b55a-d4b4b3d47037/015dc3f0-d7fd-48d7-b3f9-ab4741538715/%E3%82%A2%E3%83%BC%E3%83%88%E3%83%9B%E3%82%99%E3%83%BC%E3%83%88%E3%82%99_222x.png)

<図: パイプライン並列のミニバッチを分割>

図に示した通り、GPU が稼働していない時刻が減っており、計算効率が向上していることがわかります。しかし、図中の Bubble と書かれている部分では1個以上の GPU が休止状態になってしまいます。このような休止状態が発生するのは、誤差逆伝播を行うために全ての順伝播が完了している必要があるためです。これはバケツリレーの例に戻すと、[<図: バケツリレーの様子 (c)>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) に示す様に、一旦全てのバケツをテーブルに置き終わらなければ、反対方向には渡せないことと対応しています。

Bubble を小さくするには、マイクロバッチを小さくすれば良いです。例えば 4 並列であれば順伝播中のバブルになる時刻は最後の3ステップのみです (図中の $t_4$ ~ $t_6$ )。そのため、各ステップに係る時間が小さいほどバブルも小さくなります。ただし、GPU は大量のデータを同時に処理する際に効率がよいため、マイクロバッチが小さすぎて同時に処理するデータが少なくなると、全体としての処理が遅くなってしまうことに注意してください。

> パイプライン並列の実装
> 

PyTorch を用いたパイプライン並列を行うためのライブラリとして、PyTorch グループの管理している PiPPy というものがあります。2024 年に、このライブラリはアルファ版として PyTorch 内の  `torch.distributed.pipelining` に組み込まれています ▲注▲。

- ▲注▲
    
    書籍執筆時点でもアルファ版であり仕様変更がありうることから、パイプライン並列の実装は記載していません。
    

## 4.2.5 3D 並列化

4.2.2 から 4.2.4 でデータ並列、テンソル並列、パイプライン並列という 3 通りの並列化手法を紹介しました。3つのうち、テンソル並列とパイプライン並列は、モデルを縦横に分解する様な並列化でした。これらに対して [<図: 3D 並列化>](https://www.notion.so/4-2-f123707aadbf40d39fefe37d87bdc5ec?pvs=21) のように奥行き方向にモデルをコピーするデータ並列を加えたものを、まとめて 3D 並列化 (3D Parallelism) と呼びます。ただし、これは GPU を単に並べて実装すればよいのではありません。どの様に GPU を配置するのかといった、GPU のトポロジーも計算効率に大きく関わってきます。そのため、モデル並列と同様に 3D 並列を自身で設計するには高度な技術が必要になります。ただし大規模言語モデルの学習においては、後述する DeepSpeed 等のライブラリを使うと、比較的容易に実装が可能です。

![<図: 3D 並列化>](https://prod-files-secure.s3.us-west-2.amazonaws.com/f32ca4cc-631d-41b4-b55a-d4b4b3d47037/79d6697e-2ea4-4c3c-b9bd-50425022ed51/%E3%82%A2%E3%83%BC%E3%83%88%E3%83%9B%E3%82%99%E3%83%BC%E3%83%88%E3%82%99_382x.png)

<図: 3D 並列化>

## 4.2.6 ZeRO

3D 並列化のうち、モデル並列に分類される2つの方式は、1つの GPU に収まりきらないモデルを学習できる反面、どの GPU にモデルのどの部分を割り当てるかという、モデルの分解方法を適切に設計するのは難しいタスクになります。特に、テンソル並列とパイプライン並列を同時に用いる場合、適切な設計を行うのは並列処理に関する高度な知識を要求します。ZeRO はこの様な問題を回避して、誰でも大規模モデルの学習を可能にする方法の 1 つです。

ZeRO は Zero Redundancy Optimizer の略で、データ並列における際のメモリ利用を効率化する手法です。先述の通り、モデル並列は実装が困難なのに対し、ZeRO はどの様なモデルに対してもシステマチックに適用できるという利点があります。

ZeRO はいくつかの観点で最適化を行います。<図: ZeRO におけるモデル状態のイメージ> はそれらのうち、モデルパラメータに関する最適化の例を表しています。この例では、濃い部分のパラメータをその GPU で持っており、薄い部分はその GPU には置いていないパラメータになります。ZeRO では図に示したように、パラメータを各 GPU で重複なく保持しておき、計算に必要になったら、そのパラメータをもつ GPU と通信し、受け取ったパラメータを用いて計算したのち削除します。これによって、各 GPU が実際にメモリ上に持つパラメータ数が小さくなり、巨大なモデルの学習が可能になります。

![<図: ZeRO におけるモデルパラメータのイメージ>](https://prod-files-secure.s3.us-west-2.amazonaws.com/f32ca4cc-631d-41b4-b55a-d4b4b3d47037/1767c428-cdcc-4e89-b32a-0e9fbc07074a/%E3%82%A2%E3%83%BC%E3%83%88%E3%83%9B%E3%82%99%E3%83%BC%E3%83%88%E3%82%99_542x.png)

<図: ZeRO におけるモデルパラメータのイメージ>

このように、レイヤーごとにパラメータの授受を行うことから、パイプライン並列と混同している読者もいるかもしれません。パイプライン並列との大きな違いは、1つのデータに関する中間出力をGPU間で通信するのではなく、GPU ごとに別々の計算を行っており、モデルパラメータの方を通信している点です。別々のデータに関する計算なので、GPU間に前後関係も発生せず、パイプライン並列の様なバブルも発生しません。

ここまでは、モデルパラメータに関する最適化のイメージを説明しました。大規模言語モデルにおいて、メモリを利用する主要素は3つあります。

1. モデルパラメータ
2. 学習時の勾配情報
3. オプティマイザの状態

オプティマイザの状態というのは、Adam のような最適化手法においてモデルパラメータをアップデートするために保持しなければならない情報のことです。比較的シンプルなモーメンタム ▲注▲ でも、勾配情報と同程度の容量が追加で必要になります。Adam のように複雑なものになると、さらに数倍の容量が必要です。さらに 1, 2 の容量も加わるため、全体ではモデルパラメータの10倍以上の容量が必要になります。ZeRO の論文中では、1.5B パラメータの GPT-2 を Adam で学習するには、パラメータ数の 16 倍である 24GB のメモリが必要であると計算されています。

- ▲注▲
    
    パラメータの勾配降下方向を累積しておき、新しい勾配だけでなく累積した方向も加味してパラメータをアップデートする手法。損失関数のランドスケープ上でパラメータが慣性をつけた様な動きをする。
    

以上の様な観点から、すでに説明したモデルパラメータに関する効率化だけでは不十分であることがわかります。ZeRO では、上述の3つの要素について効率化を行っており、次の様な3つの最適化ステージを用意しています。

- Stage1: オプティマイザ状態のみ最適化
- Stage2: さらに勾配情報も最適化
- Stage3: さらにモデルパラメータも最適化

このように段階的に最適化を行うのは、ステージが上がるごとにメモリが削減される一方、GPU間の通信オーバーヘッドが増えてしまうというトレードオフ関係にあるためです。そのため、実際に用いる際には、利用可能な計算リソースやモデルサイズを加味してどのステージを使うべきかを検討します。