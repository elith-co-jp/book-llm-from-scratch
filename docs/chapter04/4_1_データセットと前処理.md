# 4. 大規模言語モデルの学習

第3章では 2017 年に発表された Transformer 以降のトークナイザやモデルに関するアップデートを紹介しました。大規模言語モデルにおいて、モデルのアーキテクチャだけでなく、データセットの量や質も重要であることが分かってきました。また、大規模言語モデルという名前の通り、モデルのパラメータ数は数十億から数百億を超える規模になっています。第4章では、このように大規模化したモデルをどのようなデータセットで、どのように学習するべきかについて説明します。実務で大規模言語モデルを学習する際には Transformers や DeepSpeed といったライブラリが利用されます。本書は大規模言語モデルをイチから作るというコンセプトですが、実際の研究・開発ではこれらのライブラリが使えることが重要になります。そこで、本章は個別の技術についてはイチから作りつつ、全体を通した動くコードとしてはライブラリを利用したものを提示します。

# 4.1 データセットと前処理

## 4.1.1 言語モデルの大規模化

- メモ
    - Scale law
    - Chinchilla law
    - FLOPs と FLOPS の違い、スループット, トークン効率について説明

## 4.1.1 言語モデルの大規模化 ver nagasawa

大規模言語モデルの性能は、モデル規模（パラメータ数）、学習データ量、そして計算量の増加に伴って向上することが知られています。この経験則を定量的に記述したものが Scaling law（スケーリング則）です。Scaling law によれば、資源を投入すればするほど性能は向上しますが、その向上幅は次第に逓減していきます。したがって、「資源を増やせばよい」という単純な図式ではなく、限られた計算資源をいかに最適に配分するかが重要となります。

このとき注目すべき指標が、スループット（throughput）とトークン効率（token efficiency）です。スループットは、単位時間あたりに処理可能なトークン数を表し、実際の学習速度を規定します。ここで留意すべき点は、理論的に必要とされる計算量（FLOPs）と、ハードウェアが実際に発揮し得る計算性能（FLOPS）、さらにそこから得られる処理速度（throughput）が必ずしも一致しないということです。学習効率を論じる際には、この乖離を踏まえる必要があります。

一方、トークン効率は「どれだけ少ない学習トークンで目標性能を実現できるか」を示す指標であり、データセットの設計や学習戦略の巧拙を直接反映します。単なるモデル拡張に頼るのではなく、いかに効率的にデータを活用するかが問われるのです。

こうした効率性の観点を統合的に検討したものが、DeepMind による Chinchilla law（チンチラ則）です。Chinchilla law は、限られた計算資源のもとでは、パラメータ数を増大させるよりも、十分に大きなデータセットを用いて学習させる方が望ましいことを明示しました。すなわち、FLOPs を「モデルの拡張」に振り向けるのではなく、「データの拡充」に投じる方が高いトークン効率を得られるという指針です。

このように、Scaling law による拡張の原理、throughput と token efficiency という計算効率の視座、さらに Chinchilla law による資源配分の最適化指針が重なり合うことで、大規模言語モデルの学習設計は初めて理論的な基盤を得るのです。次節では、その基盤の上に位置づけられる大規模データセットの準備と設計について検討します。

## 4.1.2 大規模言語モデルのデータセット

### **4.1.2.1 事前学習コーパス**

事前学習コーパスとは、言語モデルの事前学習に使用される大量のテキストデータのことを指します。これは、言語モデルが実世界のテキストデータから広範な知識を獲得するための基盤となるもので、通常、他のデータセットに比べて圧倒的な規模を持ちます。事前学習の段階では、モデルは大量のラベルなしテキストデータを利用して、言語の文法や意味、文脈に関する一般的な知識を学び、それをモデルの内部パラメータに組み込みます。これにより、言語モデルは多様な言語タスクにおいて一定の理解力と生成能力を発揮できるようになります。

**事前学習コーパスの構成要素**

事前学習に使用されるコーパスは、多様なソースから取得されます。その中には、ウェブページ、学術論文、書籍、法律文書、政府報告書、さらには小説や新聞記事まで含まれます。これらのソースは、モデルに幅広い知識を提供するだけでなく、異なる文体やトーン、専門用語など、言語の多様性を反映したデータを供給します。

さらに、特定の分野に特化したデータセットも多く存在します。例えば、医学、法律、金融などの専門分野では、それぞれの分野に特化したテキストデータが収集され、モデルがその分野に特有の知識を学習できるようにします。こうした専門的なコーパスは、一般的なコーパスとは異なり、特定の用途に焦点を当てたモデルを構築する際に重要です。

**事前学習コーパスの種類**

事前学習コーパスは、その目的や特性に基づいて、一般的なコーパスとドメイン固有のコーパスに分類されます。

1. **一般的な事前学習コーパス**

このタイプのコーパスは、幅広い分野やトピックをカバーするテキストデータで構成されており、ニュース記事、ソーシャルメディア投稿、ブログ、百科事典などが含まれます。こうしたコーパスは、言語モデルに普遍的な言語理解力を持たせることを目的としています。多様なデータソースを使用することで、モデルは異なる文脈での言語使用を学び、汎用性の高い言語処理能力を獲得します。

2. **ドメイン固有の事前学習コーパス**

こちらは、特定の専門分野に関連するデータで構成されたコーパスです。医学、法律、技術、金融などの専門領域で使用されることが多く、それぞれの分野に特有の知識や用語をモデルに学習させます。この種のコーパスは、特定のタスクで高精度なモデルを作成するために不可欠です。例えば、医療分野のコーパスを用いたモデルは、診断支援システムや医学論文の要約などで優れた成果を発揮します。

**事前学習コーパスの役割と影響**

事前学習コーパスは、モデルの性能や適用範囲に直接的な影響を与えます。以下にその主な役割を挙げます。

- **普遍的な言語理解の基盤**: 多様なテキストデータを取り込むことで、モデルは言語の文法、意味、文脈情報を包括的に学習し、自然言語の理解を深めます。これにより、異なるタスクにおいても一貫したパフォーマンスを発揮できます。
- **汎化能力の向上**: 異なる分野やトピックから得られるデータを利用することで、モデルは広範な知識を獲得し、未知のデータやタスクにも適応できる能力が高まります。これにより、新しいタスクや環境での利用が可能となります。
- **専門分野での高精度なタスク実行**: ドメイン固有のコーパスを用いることで、特定分野でのタスクに対してモデルの精度が向上します。例えば、法律文書を大量に含むコーパスで訓練されたモデルは、契約書の自動解析や法的助言などに特化した能力を持ちます。
- **多言語処理の支援**: 複数の言語をカバーするコーパスを利用することで、モデルは多言語間での文脈理解や翻訳タスクに対応できるようになります。これにより、国際的な言語タスクにおいても高いパフォーマンスを発揮できます。
- **文化的多様性の反映**: さまざまな文化圏からのデータを取り込むことで、モデルは異なる文化的背景を理解し、文化に依存した言語表現やニュアンスをより正確に処理できるようになります。これにより、より多様なユーザーに対して適切な応答が可能となります。

**事前学習コーパスの進化と現状**

事前学習コーパスの進化は、言語モデルの性能向上に密接に関連しています。初期の言語モデルは、比較的限定的なデータセットを使用していましたが、近年の大規模言語モデルは、数十テラバイト規模のデータセットを活用しています。このような大規模データセットの利用により、モデルは以前よりも遥かに広範な知識と高い性能を持つようになっています。

例えば、「Common Crawl」は、インターネット全体を網羅的にクロールして得られたデータを含む巨大なコーパスであり、現代の多くの言語モデルがこのデータセットを基盤として訓練されています。また、「OSCAR」や「CC100」などは、多言語データを提供するコーパスであり、多言語対応のモデルを訓練する際に使用されます。

さらに、最新の研究では、コーパスに含まれるデータの質やバランスがモデルの性能に与える影響についても注目が集まっています。たとえば、偏ったデータセットはモデルにバイアスを生じさせる可能性があり、その結果、特定の集団や言語に対して不公平な処理を行うリスクがあります。このため、データの選定やフィルタリングプロセスも非常に重要な要素となっています。

以下の表では、一般的に使用される事前学習コーパスを示します。これらのコーパスは、それぞれ異なる言語やデータソースから構成されており、言語モデルの訓練において重要なリソースを提供しています。

| コーパス | 言語 | データ容量 | データ内容 |
| --- | --- | --- | --- |
| Common Crawl | 多言語 | - | ウェブページ (雑多) |
| CC100 | 多言語 | 2.5TB | ウェブページ (雑多) |
| C4 | 英語 | 12.7TB | ウェブページ (雑多) |
| mC4 | 多言語 | 251GB | ウェブページ (雑多) |
| OSCAR | 多言語 | 8.4TB | ウェブページ (雑多) |
| CulturaX | 多言語 | 27.0TB | ウェブページ (雑多) |
| RedPajama-V2 | 多言語 | 30.4兆トークン | - |
| S2OCR | 英語 | 81.1MB | 学術論文 |
| The Stack | プログラミング言語 | 6TB | ソースコード |
| Wikipedia | 多言語 | - | 百科事典 (雑多) |
| FinGLM | 中国語 | 69.0GB | 金融関連 |
| Medical-pt | 中国語 | 632.8MB | 医療関連 |
| Proof-Pile-2 | 英語 | 55兆トークン | - |

### **4.1.2.1** インストラクションチューニングデータセット

大規模言語モデル（LLM）は、膨大なテキストデータを使用した事前学習によって、言語に関する豊富な知識を獲得し、高度な自然言語処理能力を身につけています。しかし、特定のタスクに適用するためには、追加の学習が必要であり、これをファインチューニングと呼びます。ファインチューニングには、タスクに特化したデータセットを使用することが重要です。この種のデータセットは、ユーザの指示に従って応答を生成するために設計されており、インストラクションデータセットと呼ばれます。インストラクションデータは、特定のタスクに対する「指示入力」とそれに対応する「応答出力」のペアで構成されています。指示には、要約、質問応答、翻訳など多様なタスクが含まれ、応答はその指示に従ってモデルが生成する結果です。

インストラクションデータの作成方法には、主に二つのアプローチがあります。まず一つ目は、人間が手動で作成する方法です。この方法では、高品質で人間の意図に合致したデータを得ることができますが、その反面、作成には膨大な時間とコストがかかるという課題があります。もう一つは、LLM自身がデータを生成する方法です。このアプローチでは、大量のデータを短時間で生成できますが、データの品質が一定しない場合があり、人間の直感とは異なる結果が得られることもあります。

インストラクションデータの元となるデータソースとしては、既存のデータセットの活用や、テーブルデータのような構造化されたデータの変換が挙げられます。また、タスクの種類も多岐にわたり、具体的には以下のようなタスクがあります。

- **Closed QA**: 提供された質問に基づいて、正しい選択肢を選択する。
- **Open QA**: 提供された質問に基づいて、適切な回答を生成する。
- **要約**: 与えられた文章を簡潔にまとめる。
- **生成**: 指示に基づいて新たなテキストを一から生成する。
- **翻訳**: 異なる言語間での翻訳を行う。
- **数学**: 数学に関する問題を解く。
- **コード**: コードの生成、修正、理解など、プログラミングに関連する問題を解決する。

これらのタスクを処理するために、多くのインストラクションデータセットが存在します。以下にその例を示します。

| データセット名 | 言語 | 作成方法 | データ数 |
| --- | --- | --- | --- |
| databricks-dolly-15K | 英語 | 人手 | 15k |
| databricks-dolly-15k-ja | 日本語 | 人手+翻訳AI | 15k |
| OASST1 | 多言語 | 人手 | 161k |
| Alpaca_data | 英語 | LLM | 52k |
| ichika-instruction-003-001 | 日本語 | 人手 | 3k |

これらのデータセットを用いてモデルをファインチューニングすることで、モデルは特定のタスクにおける意図を理解し、適切な応答を生成する能力を得ることができます。モデルのパラメータを適切に調整することで、一般的な言語知識を維持しつつ、特定のタスクに特化した能力を持たせることができるのです。

### 4.1.2.3 嗜好データセット

嗜好データセットは、特定の指示に対する複数の回答に対して、どの選択肢がより好ましいかを示すデータの集合です。これらのデータセットは、指示に対する異なる回答ペアと、それに対する人間や高度な言語モデル（LLM）からのフィードバックで構成されています。このフィードバックにより、特定のタスクや文脈においてどの回答が相対的に適切であるかを判断することができます。

選好を評価するためには、いくつかの方法が使用されます。たとえば、投票、ソート、またはスコアリングといった比較方法があります。これらの手法は、選好を明確に表現するために、人間の評価者や大規模言語モデル（LLM）によって行われます。嗜好データセットは特に、大規模モデルのアライメントプロセスで利用され、人間の期待や基準により近い出力を生成するためにモデルを調整する際に重要な役割を果たします。

人間からのフィードバックは、現実世界での選好や直感に基づいており、モデルの出力を現実的なものに近づけるために有用です。しかし、その一方で、個々の評価者の主観性や、異なる評価者間の一貫性の欠如といった問題が生じる可能性があります。また、このプロセスは手間がかかり、コストが高くなることもあります。

一方、モデルによるフィードバックは、事前に学習された広範な知識を活用し、迅速かつ低コストでのアノテーションが可能です。ただし、モデル固有のバイアスが含まれるリスクや、人間によるフィードバックと比較して信頼性が劣る可能性もあります。そのため、モデルのトレーニングには、さまざまな形式とソースから得られた選好データを組み合わせる、包括的なアプローチが効果的とされています。

さらに、強化学習を取り入れた手法、特にRLHF（Reinforcement Learning from Human Feedback）は、これらのフィードバック信号に基づいてモデルを最適化するための強力なツールです。この手法により、モデルはフィードバックを活用して自己改善を行い、より人間に近い応答を生成することができます。

次に、代表的な嗜好データセットを表4.3に示します。これらのデータセットは、言語モデルの性能向上に寄与するための重要なリソースであり、各データセットは特定の言語やタスクに焦点を当てています。

| データセット名 | 言語 | データ数 |
| --- | --- | --- |
| Chatbot_arena_conversations | 多言語 | 33k |
| hh-rljf | 英語 | 169k |
| hh-rlhf-49k-ja | 日本語 | 49k |
| OASST1_pairwise_rlhf_reward | 多言語 | 19k |
| Stack-Exchange-Preferences | 英語 | 11M |
| Alpaca_comparison_data | 英語 | 51k |

これらのデータセットを使用することで、モデルは多様な状況における人間の好みを理解し、より洗練された出力を生成することが期待されます。

## 4.1.3 データの前処理

LLM の学習に使われるデータはインターネットから集めたものなど、文章としての質が担保されていない場合が多いです。また、文章としての質が良くても個人情報や機密情報を含んでいる場合は削除しておかないと、LLM 利用時に出力されてしまうといった問題もあります。

以上のような問題に対処するために、収集されたデータセットはそのまま使うのではなく、前処理を行った後に利用します。よく用いられる前処理は以下の4つです。

- **テキスト正規化**
- **品質フィルタリング**
- **重複除去**
- **プライバシー保護**

以降ではこの4つについて具体的にどのような方法が用いられているのかを説明します。

テキスト正規化はテキストに含まれるスペースや、カギ括弧の種類などを揃える処理のことです。これらの表記揺れは、LLM の学習時にはノイズになってしまうので除去する必要があります。ここでは、 `neologdn` というライブラリを利用して、テキスト正規化を試してみましょう。

> neologdn を用いたテキスト正規化 ver Nagasawa
> 

```
import neologdn

def neologdn_preprocess(text):
    # 1. neologdnによるデフォルト正規化
    normalization_text = neologdn.normalize(text)
    
    return normalization_text 
```

<コード: neologdn を用いたテキスト正規化コード>

品質フィルタリングは、低品質のテキストを学習データから除外する処理です。この処理では以下の3通りの方法が用いられます。

1. ヒューリスティックを用いた手法
2. 分類モデルを用いたの手法
3. LLM を用いた手法

ヒューリスティックを用いた手法というのは、特定のキーワードを含んでいたら除外する、統計的特徴に基づいて除外するといった手法です。

分類モデルを用いた手法は、テキストの品質を評価する機械学習モデルが別途学習しておき、そのモデルの判定結果をもとにテキストを除外します。

LLM を用いた手法ではパープレキシティ▲注▲のような評価指標を基準として、不自然な文章を除外します。

- ▲注▲
    
    第5章で詳しく説明します。ここでは、LLM にとっての与えられた文章の自然さと捉えてください。
    

重複除去は名前の通り、重複するテキストを除外する処理です。この処理は主に2つの理由から行われます。

- 学習データに重複が含まれるとモデルの能力に悪影響を与える可能性がある
- 学習データとテストデータを分けた際に、重複があると適切に評価できない

重複除去は、文書レベル、文レベル等の複数のレベルで行われます。文書レベルでは、文書に関する特徴量をもとに同じような文書が検出されます。文レベルでは、反復フレーズなどが検出されます。

最後にプライバシー保護では、電話番号、氏名、住所といった個人情報や、パスワード、シークレットキーといった機密情報を検出し削除します。このような情報の検出は正規表現を用いたルールベースの手法や、固有表現抽出 (Named Entity Recognition, NER) と呼ばれる自然言語処理タスクを解く機械学習モデルを利用した方法が用いられます。ただし、これらの方法でも完全には除外しきれないため、第5章で扱うアラインメントによって、個人情報を聞かれても答えないようにチューニングすることも重要になります。

## 4.1.4 前処理の実装

ここでは 4.2 節以降の事前学習で利用するデータセットを作成します。簡単のため、複雑な前処理は完了しているデータとして、青空文庫のテキストをもとにした globis-university/aozorabunko-clean データセット▲注▲を利用します。

- ▲注▲
    
    https://huggingface.co/datasets/globis-university/aozorabunko-clean
    
    グロービス経営大学院が CC-BY ライセンスで公開。
    

```markdown
生とは冷たい幸福の結ぶ氷であり、
死とはあらゆる人間の虚栄をとかす霜解けである。
――「クリストレロの諷刺詩」一五九八年、Ｔ・Ｂ作
```

```markdown
生とは冷たい幸福の結ぶ氷であり、
死とはあらゆる人間の虚栄をとかす霜解けである。
ー「クリストレロの諷刺詩」一五九八年、T・B作
```

違いの例：

- ダッシュ `――` ↔ 長音符 `ー`

### 補足：トークナイザについて

本書の進め方として、トークナイザの学習・保存は 4.3 節（事前学習）側でまとめて実施します。本 4.1 節ではテキストの正規化・連結・チャンク化などの「前処理」に焦点を当て、トークン化は行いません。

```

# データセットのロード
raw: DatasetDict = load_dataset("globis-university/aozorabunko-clean")

# 本文テキストのカラム名
TEXT_COL = "text"

def normalize_ja(text):
    # 1. neologdnによるデフォルト正規化
    normalized_text = neologdn.normalize(text)

    # 全角英数 → 半角（A-Z/a-z/0-9 のみ最小実装）
    def z2h_alnum(match):
        ch = match.group(0)
        return chr(ord(ch) - 0xFEE0)
    normalized_text = re.sub(r"[Ａ-Ｚａ-ｚ０-９]", z2h_alnum, normalized_text)

    # クオートの半角化（任意）
    normalized_text = normalized_text.replace("＂", '"').replace("＇", "'")

    # 三点リーダの統一
    normalized_text = normalized_text.replace("･･･", "…").replace("・・・", "…")

    # 連続空白の圧縮
    normalized_text = re.sub(r"\s+", " ", normalized_text).strip()

    return normalized_text

# データセット全体に適用
def apply_normalize(batch):
    texts = batch[TEXT_COL]
    return {TEXT_COL: [normalize_ja(t) for t in texts]}

# batched=True で速度改善、説明を付与
norm_ds = raw.map(
    apply_normalize,
    batched=True,
)

# 文書境界セパレータ付与＆連結
# 事前学習用に文書間の境界を示すセパレータ
SEP = "\n\n<|doc|>\n\n"

def make_long_string(dsdict, split, , col=TEXT_COL):

    # DataSetsの列アクセスは高速なので、そのままスライスで取り出す
    texts = dsdict[split][col] 
    
    # 空文字などがあっても素直に連結
    return SEP.join(texts)

long_text = make_long_string(norm_ds, split="train")

# 学習用チャンク化（プレトークナイズ前）
block_size = 2048

def chunk_text(s: str, size: int):
    # ここでは単純に「文字数」で分割
    for i in range(0, len(s), size):
        yield s[i : i + size]

# 文字列を2048文字ごとに分割し、Dataset形式化
chunks = list(chunk_text(long_text, block_size))
out_ds = Dataset.from_dict({"text": chunks})

```
